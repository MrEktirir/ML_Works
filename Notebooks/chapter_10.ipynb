{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perceptron\n",
    "\n",
    "* The perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron called a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scikit-Learn provides a Perceptron class that can be used pretty much as you would expect—for example, on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0) # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new) # predicts True and False for these 2 flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data,\n",
    "    housing.target,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    mlp_reg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053326657967967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "A = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(A.data, A.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.90357396\n",
      "Validation score: 0.333333\n",
      "Iteration 2, loss = 0.90026353\n",
      "Validation score: 0.333333\n",
      "Iteration 3, loss = 0.89697773\n",
      "Validation score: 0.333333\n",
      "Iteration 4, loss = 0.89371710\n",
      "Validation score: 0.333333\n",
      "Iteration 5, loss = 0.89049354\n",
      "Validation score: 0.333333\n",
      "Iteration 6, loss = 0.88729736\n",
      "Validation score: 0.333333\n",
      "Iteration 7, loss = 0.88412733\n",
      "Validation score: 0.333333\n",
      "Iteration 8, loss = 0.88098044\n",
      "Validation score: 0.333333\n",
      "Iteration 9, loss = 0.87786561\n",
      "Validation score: 0.333333\n",
      "Iteration 10, loss = 0.87478224\n",
      "Validation score: 0.333333\n",
      "Iteration 11, loss = 0.87170958\n",
      "Validation score: 0.333333\n",
      "Iteration 12, loss = 0.86867681\n",
      "Validation score: 0.333333\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=[5,8],\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    verbose = True,\n",
    "    alpha=0.01,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    mlp_clf\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 7,  4,  0],\n",
       "       [ 2, 10,  0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's look data shapes & types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For simplicity, we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0 (this also converts them to floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train/255.0, X_valid/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With MNIST, when the label is equal to 5, it means that the image represents the handwritten digit 5. Easy. For Fashion MNIST, however, we need the list of class names to know what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For example, the first image in the training set represents an ankle boot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let’s build the neural network! Here is a classification MLP with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\")) #Hidden 1\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\")) #Hidden 2\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of adding the layers one by one as we just did, it’s often more convenient to pass a list of layers when creating the Sequential model. You can also drop the Input layer and instead specify the input_shape in the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model = tf.keras.Sequential(\n",
    "#    [\n",
    "##        tf.keras.layers.Input(shape=[28, 28]),\n",
    "#        tf.keras.layers.Dense(300, activation=\"relu\"), #Hidden 1\n",
    "#        tf.keras.layers.Dense(100, activation=\"relu\"), #Hidden 2\n",
    "#        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model’s summary() method displays all the model’s layers,⁠ including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (None means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. Here we only have trainable parameters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that Dense layers often have a lot of parameters. For example, the first hidden layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters! This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can easily get a model’s list of layers using the layers attribute, or use the get_layer() method to access a layer by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.5857680e-03, -4.8993193e-02,  4.7253907e-02, ...,\n",
       "        -5.3038381e-02,  6.1439350e-02, -4.3981221e-02],\n",
       "       [ 1.0294840e-03,  6.6091046e-03,  1.3100646e-02, ...,\n",
       "        -4.9400348e-02, -1.4953315e-05,  3.8531534e-02],\n",
       "       [-4.4665672e-02, -2.1986958e-02,  7.1816295e-02, ...,\n",
       "         5.5079550e-02, -2.8016478e-02,  7.3282838e-02],\n",
       "       ...,\n",
       "       [ 5.1423445e-02,  6.8225980e-02,  1.4430292e-02, ...,\n",
       "         4.3125816e-02,  2.4836369e-02, -2.4854317e-03],\n",
       "       [ 1.5724570e-02, -6.8840928e-02, -1.2824185e-02, ...,\n",
       "        -4.2081602e-02, -4.2604499e-02,  4.5827553e-02],\n",
       "       [-6.6307820e-02,  2.3779027e-02,  3.9201826e-02, ...,\n",
       "        -2.1036528e-02,  4.9861297e-03,  6.9705680e-02]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer = \"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6870 - loss: 0.9856 - val_accuracy: 0.8286 - val_loss: 0.5084\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8242 - loss: 0.5081 - val_accuracy: 0.8370 - val_loss: 0.4553\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - accuracy: 0.8414 - loss: 0.4539 - val_accuracy: 0.8430 - val_loss: 0.4325\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8532 - loss: 0.4231 - val_accuracy: 0.8482 - val_loss: 0.4176\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8603 - loss: 0.4011 - val_accuracy: 0.8542 - val_loss: 0.4051\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8650 - loss: 0.3838 - val_accuracy: 0.8570 - val_loss: 0.3937\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8708 - loss: 0.3694 - val_accuracy: 0.8602 - val_loss: 0.3850\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8734 - loss: 0.3572 - val_accuracy: 0.8606 - val_loss: 0.3788\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8771 - loss: 0.3460 - val_accuracy: 0.8632 - val_loss: 0.3729\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8806 - loss: 0.3363 - val_accuracy: 0.8660 - val_loss: 0.3676\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11ms/step - accuracy: 0.8832 - loss: 0.3275 - val_accuracy: 0.8676 - val_loss: 0.3628\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8863 - loss: 0.3191 - val_accuracy: 0.8686 - val_loss: 0.3596\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8890 - loss: 0.3116 - val_accuracy: 0.8688 - val_loss: 0.3572\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8916 - loss: 0.3044 - val_accuracy: 0.8702 - val_loss: 0.3554\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.8938 - loss: 0.2976 - val_accuracy: 0.8708 - val_loss: 0.3541\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8959 - loss: 0.2911 - val_accuracy: 0.8710 - val_loss: 0.3522\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8973 - loss: 0.2848 - val_accuracy: 0.8720 - val_loss: 0.3504\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.9000 - loss: 0.2789 - val_accuracy: 0.8734 - val_loss: 0.3494\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.9021 - loss: 0.2733 - val_accuracy: 0.8732 - val_loss: 0.3487\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2678 - val_accuracy: 0.8726 - val_loss: 0.3491\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9063 - loss: 0.2627 - val_accuracy: 0.8736 - val_loss: 0.3484\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - accuracy: 0.9082 - loss: 0.2576 - val_accuracy: 0.8762 - val_loss: 0.3474\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9094 - loss: 0.2528 - val_accuracy: 0.8746 - val_loss: 0.3500\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.9118 - loss: 0.2482 - val_accuracy: 0.8762 - val_loss: 0.3478\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2434 - val_accuracy: 0.8766 - val_loss: 0.3485\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9149 - loss: 0.2390 - val_accuracy: 0.8764 - val_loss: 0.3484\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9162 - loss: 0.2348 - val_accuracy: 0.8772 - val_loss: 0.3470\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.9187 - loss: 0.2304 - val_accuracy: 0.8774 - val_loss: 0.3503\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 21ms/step - accuracy: 0.9195 - loss: 0.2267 - val_accuracy: 0.8772 - val_loss: 0.3503\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.9213 - loss: 0.2223 - val_accuracy: 0.8778 - val_loss: 0.3538\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The fit() method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). If you use this dictionary to create a Pandas DataFrame and call its plot() method, you get the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Epoch'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFBCAYAAABEo8fdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAABHyUlEQVR4nO3dd3xV9f3H8dc3m71liqDIUBnuogXjRkv1pxZxK0Vx1FFX3UpFW3er1oUbhSp1V3EUJaIVFUQEBUGKKIlhCkgYWff7++OTw70JuVmEnJvk/Xw8zuOee+b3HsL93O923ntEREQkPElhJ0BERKSxUzAWEREJmYKxiIhIyBSMRUREQqZgLCIiEjIFYxERkZBVGoydc08551Y6576Os9855x5wzi12zs11zu1T+8kUERFpuKqSM34GGFbB/mOA3UuWMcAj258sERGRxqPSYOy9nw78XMEhxwMTvPkUaO2c61xbCRQREWnoaqPOuCuwLOZ9dsk2ERERqYKUuryZc24MVpRNRkbGvt27d6/L29d7kUiEpCS1uasOPbPq0zOrPj2z6muMz2zRokWrvfcdyttXG8E4B9g55n23km3b8N6PB8YD9OnTxy9cuLAWbt94ZGVlkZmZGXYy6hU9s+rTM6s+PbPqa4zPzDn3Q7x9tfGz5A3grJJW1b8C1nvvc2vhuiIiIo1CpTlj59w/gUygvXMuG7gFSAXw3j8KTAGOBRYDm4BROyqxIiIiDVGlwdh7f2ol+z3wh1pLkYiISCPTuGrPRUREEpCCsYiISMgUjEVEREKmYCwiIhIyBWMREZGQKRiLiIiETMFYREQkZArGIiIiIVMwFhERCZmCsYiISMgUjEVEREKmYCwiIhIyBWMREZGQKRiLiIiETMFYREQkZJXOZywiIiJxRCKwejVs2QL5+dHXzp2ha1fIy4N33rFtFVAwFhGRxOc9FBVFAx5A+/b2Ons2rFsHmzdHly5d4PDDbf9f/wo//xzdV1AABx8MF1xg+487DjZtgsJC21dYCCNGwDXX2P369LFtwf4tW+DKK+H22+26HTtum96//AWuu84C9YgRlX48BWMRESmtqMgCTvPm9n7FimjuL1iKi+Goo2z/9OmweLEFqmDJyICLL7b9TzwBc+eW2r9bfj5kZtr+Sy6BWbMs8AXLHnvAG2/Y/gMPhJkzLSAHDjsM3n/f1keMgCVLSn+G446LBuMHHoD166FJE1vS0qBTp+ix69bZ50lNtc+cmgotW9q+1FQ45BB7TU21czMyYMgQ29+iBTz0EKSn2/Zg6dvX9nfpYp89Pd2CehwKxiIiiSYSsVxYSgokJ8PGjbBqVelgl58PAwdC06awaJEFq82bLYcX5ACvvNKCxWuvwb/+VXrfpk2QlQXNmsGtt8KDD0YDbVFRNB3Owc03w/jxpdPYrJkVwQI89hhMmlR6f6dO0WD83nswdaoFsrQ0SE2lWbt20WNTUiyd7dtb0EpPh913j+4/80w4+mjbHgTDHj2i+595xoJp06bRgNu6dXT/Tz/Z54hn+vT4+5KS4Nln4+9PT4eLLoq/Py0N+vePv7+EgrGISGWKi6PFoLEBrWdP6NiR1HXr4LnnSu/ftAlGjoS99oKvvrJiy9h9mzbBI4/A4MGWAzz77GigDYLhjBnwq1/Biy/C6NHbpmvePLv+O+/AZZdtu/+ccyzIZWfDZ5+VDlYdOtjnArvGyJHb5u4iEfsxcO65cMQRpfc1aRK9z333WVFwEGyDJTB58jZJm5uVRWbw5m9/q/j5B0E9niCXGk9FgThBKBiLSP0SiURzcMnJ0KqVFV/Onl062G3eDL17w7772vpdd227/8QT4aSTYPlyGD68dJ3j5s1WJ/iHP8C331rAKuuJJ2D0aDJ++smOi+UcDBhg523caEWVTZpYQGzeHHbayYIfwC67WO4vLS2a+0tLg27dbP+QIfD009sGu112sf2nnw7DhkUDbdOmFjCTSjrMXHxxxQHtxBNtiWf//W2Jp7w6U6kWBWMRqR2FhdEc38aNtqSmWt0fwL//bUEvdv+uu0ZzfKNGQW5u6XrJI46Ae+6x/V27Wr1lQUH0nuedFy0+3W+/bdN0+eUWjCMRGDvWAl0QrJo0sVwnWGDbaadoMAuWPfe0/V26WL1j2f0lxY8bd9sNvvsueu2mTe2aQY7soINgwYL4z27gQLt+PLvvXrrYtqx27WyRekvBWKSh8t4CV5D7ys2FlSujAXPTJium/L//s/2vvALz5rHrt9/a+ubNVsR53322/6qr4L//jeYat2yxYDptmu0fMsSKQmMNHgyffGLr110H33wT3ZeUBL/5TTQYr1hhRcEZGdCmjb126RI9/pxzLKjGFpUGdXHOWbAPik+DYNuhg+1v2tSKfpOTy39WbdvClCnxn2WbNtbIKI5Iejr06hX/fJFKKBiLhCUSsYDYpIkFieXLrUXqhg2WawwC5llnWTB57z0LGMH2oLj1tdcs4P71r5ZLjA22YEHIObjpJnjyydJpaNnSWpmC1eu9+CLdUlOjwSy2kUxysgXn2BxkUEwKVkw7YoQ17GnWzK4R22L1rbcsAAf7Y3OOUHEwBCsyrsjw4fH3ORc/EIskAAVjkcp4b1/mmzfDsmXRItZgOfhgqzNbsABeeilaDJuXZ8vtt1sR48svw7XXRrdv3GjXXrDAukH8859wxRXb3v83v7HA9sUXVm8YFIMGS36+BePu3S132qRJNBg2bRpthHP++XDssbYtdn/g2Wdh4kSmf/QRmUGXk1h33lnxczrzzIr3xwZuESlFwVgajkgE1q4tlTNsNW+eFaV2726d8ydNigbCICieeSYMHQpff231lsH24LhJk+B3v4OPP472q4w1ZQoccwwsXGhdQNLSoo10mjeHX36x49q3hwMOiG4PlrZtbf8JJ1hjnxYtSgfMnXay/dddZ0s8p59uSzyVNcIJirNFpM4pGEt4vLdAFYlYnZz3lrNcu7b0kpkJp55qAXbYsNKNhDZtskY6119vdY6xdYzA3mB1m1dfbcE4qPdLSooGwyAX2KSJBb5dd7XtzZrZa+/etr9/f3j++dLFsM2awW672f7hw62ONjW1/M97yCG2xNOjR+liYRFpNBSMZftEIlZMGvQ5/OQTq/uMDaaxLWaPPBKWLo3ui0SsTvTZZ60o+Mwzo2O4pqVZkA66TaSl2eAAnTqVLqYdMMD2t2kD999fat9X333HwJEjbX+PHtaAqXlza+hTtu/hbrtZvWY8nTpVnPNM0X8nqbrCQit82bIlOs5FevqO/TOKRKLjhQRje0QipRfvq74N7L9R7FLetvKW779vStu2loaiImtLWN5rvH3ex1+g4n1l01jVNDtn1ygutiUSia5X9j4SqfjfRt8ejZn39j9y06Zot4jZs+HHHy3HGiwtWkRzlH/4A3z+eTSYrltndabBCDajR1ufzEByMhx/fDQYd+liLVzbtLGlbdtoMA3u37KlbW/SpHTATEmBDz6I/3kyMuDSS0ttWpuVZUXUwflB61rZYYIvq/z8bQeMKm899n1QPV/dL0iwwo7kZFvircd7n5RkaS4stC/78l4r2jd3blc+/bR07UbZ2o6y72N7aMVKSoqOvREbpONtC4Zrjl2CuQrKbissrJu/gao5IOwE1Jngb60iCsYNQfANBjYs3rff2tB5q1fb65Yt8I9/2P6rr7ai4CDQFhVZ/83sbNt/883b5g779StdvNuhgzVICgJqUIwLMHGi/dW1aWPD0bVoUTqgVjSsHET7pIbI++gXbU1+eQdLUVHFQaii4FRQUP1f3bHrQc6lOukNllWr9qJly+oFo9hjgqDauFgf4Njaj9iajvbtrWAmeB+7pKdH5x6IF1DL7tu0yX4L5+fbb8wgMJcdUbJs8I59n5ERHW0z+EHiXHS9om3B9pr8vwiWBQu+YeDAPbemobzXePuSk6v2A62i3G1N0hyo7Mdd7PvYr7+KBgJTME5ExcVWv7lypQXTlSstdwnW//PFF217EHDXrLHuMOnpNr5sEHjBcpedOkUD9i67WIvbli2jSzDzCcDdd8O4cba9VSv73x3bsOfBBytO+z77VPvjem9fKhs2WK6h7OvmzVX/5V922+rVe9OkSdWCSLBeWXFSGKryHz9Yj/2yrElR3KZN6VvHzE9JsRL/lJTo+2C8/LLbgteyg0jFWy/vffBFCdX7ggyKUSv6kVLR+0gk+uVf0WeL9/lnz/4vRx99MOnp9WLkxYSQlbVqa3MNUTCuO0EwzM628WaDIBsE1XvuseLUhx+2YevKZi2CGUmys2HOHMud9uplIwh16GCRJD3dxqc9+2zb1qFD6a4rUPkYr/36Vfox8vOrXhwXLLEBtrz1YCje6khNrfzXf5Mmxey0U9W/ZGNfU1Jq9qs7WILAVJ2AFKynppYOrHUpK+uL8rs2SVz/+18hGRlhp0LqMwXj2rBpk337NmkC339vLW6XLbMlO9teX3vNWu3+979wyinRc9u1s6C5bp0F4333hRtvtFa9QUDdaScrSv7hB7j0UvLPv5RffrGxGra+Tg3e9yq9veQ1Ly/a6KGihhnx3m/eHA22wdjyVRF0eW3Rwpbmza0Ee+edS2+LfY1db9bMrlG2eC0trWpBKitrrgKLiCQ8BeOqCJogZmRATo4V4wZBdtkyq7x57jk44wwbcvDmmy2A7ryztdDNzKSwdQdWZMP6nYex4fnFbEhtS15SSzZsSrbc4duwYTJs2HAgeXkHsuHbbYtr16w5aGuRbWXS06MlzS1bRuum4tUDVVRXFPzOKK8urKJtzZpp0CMRkapQMC6rqMi658ydG13mzbOhBK+91gLzSy9ZoN1lF/j1r/ml/a7ktDyQ7P9Azo8HkjO2gJwVqeTkQE425HwGKx4KSp5blSzbChp/lM0ldu9urxs2rKZfvy6lgmy8V43fICJSfzTeYFxYaC2Pg4Dbo4cNF+g9HHEEvrCQ9a17sKLPUJYfczorNh/G8gcgN3dnco5dbYF2EeRMi86vbZKBZNq2tZLlrl1h0CB77dLFimjjFcmW7clTVlbWIjIzu8Q/QERE6qXGE4w3bYKmTcnLg+W/Gc3yT5awvKgdK+jI8qSurOjVl+VvwYoVqSxv+wsr1qWTv87BZ9jysl0mJcWCateuNiDTsGHRoNutWzToxs67LSIiUpEGE4wjEWucnJNTsvxvC9mfZpMz72dylhWTU9CBnIxeJcMEl565JglPh/WOTj/aYE99+2bQsaP1CCr72rZt3bduFRGRhq3eBOP8fPjf/6xkefFiaz+VnR0Nvrm5nqKi2DLeDJLpQWcy6NpyA/12L+aIQyN07ZZEly6lg2z79k4NjUREJDQJFYyLi61x8qJF2y5Ll5buetu8uadbh3y6pqzg0Mh3dHVf0vXGM+m6bye6/vAJ3RZnsdNvDyR5yEHQpFton0lERKQyoQXjzZuTeeqp0gF38eLS3XZatLCRFn/1K5tLoHdvW3qt/4LWpx0L36+0A3v3hvOOgLPzoBfAQSWLiIhI4gstGC9b1pTRo22koV69LJ4ee2w04PbubUXI5bYuXrurzf5zxBFw+OHWzUhERKSeCi0Yd+26mY8+sj60VaqvLSqCP/0J/vhHO+n553d0EkVEROpEaO2CmzUromfPKgZi723M5b/9DaZO3eFpExERqUv1o5PO3/5mEyhcfTX8/vdhp0ZERKRWJX4wfvlluOoq+N3v4I47wk6NiIhIratSMHbODXPOLXTOLXbOXVvO/u7OuWnOuS+dc3Odc8fWSuoiEbj3XmtOPWGCRtsQEZEGqdIGXM65ZOAh4EggG5jpnHvDez8/5rAbgcne+0ecc3sAU4Ae2526pCR4913r76TxJUVEpIGqSlbzAGCx936J974AeAE4vswxHmhZst4K+Gm7UrVmjTXY2rjROhu3b79dlxMREUlkVena1BVYFvM+GziwzDFjgfecc5cAzYAjyruQc24MMAagQ4cOZGVlbXNMUkEBA666ipbffsuX/fqxoW/fKiSxccjLyyv3mUl8embVp2dWfXpm1adnVlpt9TM+FXjGe3+vc24w8Jxzbi/vfST2IO/9eGA8QJ8+fXxmZmbpq0QicPrpNn/wCy+w78iRtZS8hiErK4ttnplUSM+s+vTMqk/PrPr0zEqrSjF1DhA7xFW3km2xRgOTAbz3M4AMoPplyzfcAC+8AHfeCQrEIiLSSFQlGM8EdnfO9XTOpQGnAG+UOeZH4HAA51w/LBivqlZKVq2CJ5+E88+3/sQiIiKNRKXF1N77IufcxcC7QDLwlPf+G+fcrcAs7/0bwJXA4865y7HGXOd4HzvHUhV06ABffAGdO8cZkFpERKRhqlKdsfd+CtZdKXbbzTHr84GDa5SCr76C11+Hm27ShA8iItIohTuKRnY2/OY38Pjj1p1JRESkEQpt1iYXiVgg/uUX+Phj9SUWEZFGK7RgnPHTTzay1pQpMGBAWMkQEREJXWjBOGXTJnjiCTjqqLCSICIikhBCqzPe2LMnjB4d1u1FREQSRmjBOJKaGtatRUREEormJBQREQmZgrGIiEjIFIxFRERCpmAsIiISMgVjERGRkCkYi4iIhEzBWEREJGQKxiIiIiFTMBYREQlZaME47eefYcaMsG4vIiKSMEILxumrV8Phhysgi4hIoxduMXVBAWRlhZoEERGRsIUbjFNTITMz1CSIiIiELdxgfPXVMHhwqEkQEREJW2jB2CclQU5OWLcXERFJGKEF4+ImTVRfLCIiQpjBuFkzaNsW8vLCSoKIiEhCSAnrxgWtW8PMmWHdXkREJGGEPwKX92GnQEREJFThBuObb4ZBg0JNgoiISNjCDcZt2sDcuZCdHWoyREREwhRuMA4G/Pjww1CTISIiEqZwg/GAAdC6tbo4iYhIoxZuME5OhiFDlDMWEZFGLbSuTVudfTbMnw/FxRacRUREGpnwg/FJJ9kiIiLSSIXfzxjgl1/g66/DToWIiEgows8ZA5xxBixcaIuIiEgjkxg540MOgUWLIDc37JSIiIjUucQIxupvLCIijVhiBONBg6BlS/U3FhGRRikxgnFyMgwdqmAsIiKNUmI04AL485/Vz1hERBqlxAnG++wTdgpERERCkRjF1IHXXoNJk8JOhYiISJ1KnJwxwOOPw5IlcNppYadERESkziRWzjgzE779FpYvDzslIiIidSaxgvEhh9ir+huLiEgjkljBeJ99oHlzBWMREWlUqhSMnXPDnHMLnXOLnXPXxjnmZOfcfOfcN865mrXCSkmx+Y2/+65Gp4uIiNRHlTbgcs4lAw8BRwLZwEzn3Bve+/kxx+wOXAcc7L1f65zbqcYp+te/oFmzGp8uIiJS31QlZ3wAsNh7v8R7XwC8ABxf5pjzgIe892sBvPcra5wiBWIREWlkqhKMuwLLYt5nl2yL1Rvo7Zz7r3PuU+fcsO1K1ZgxcMst23UJERGR+qK2+hmnALsDmUA3YLpzrr/3fl3sQc65McAYgA4dOpAVZyzq/l99RcZ77zHz0ENrKXkNQ15eXtxnJuXTM6s+PbPq0zOrPj2z0qoSjHOAnWPedyvZFisb+Mx7Xwh875xbhAXnmbEHee/HA+MB+vTp4zODqRPLOvFEuPZaMvfYA3aqefVzQ5OVlUXcZybl0jOrPj2z6tMzqz49s9KqUkw9E9jdOdfTOZcGnAK8UeaY17BcMc659lix9ZIapyr4B5o+vcaXEBERqS8qDcbe+yLgYuBdYAEw2Xv/jXPuVufccSWHvQuscc7NB6YBV3vv19Q4VfvsYw25VIQhIiKNQJXqjL33U4ApZbbdHLPugStKlu2XmgrnnAPdu9fK5URERBJZYk0UEesf/wg7BSIiInUisYbDLKuoCNavDzsVIiIiO1TiBuNIxIqpb7wx7JSIiIjsUIkbjJOSoH9/NeISEZEGL3GDMVgXp6+/htWrw06JiIjIDpPYwTiY31j9jUVEpAFL7GC8337QtKmKqkVEpEFL3K5NAGlp1sWpX7+wUyIiIrLDJHYwBhg1KuwUiIiI7FCJXUwN1td46lT45puwUyIiIrJDJH4wjkTguONg/PiwUyIiIrJDJH4wTkuDgw9WIy4REWmwEj8Yg3VxmjsX1tR8IigREZFEVT+CcTC/8UcfhZoMERGRHaF+BOP994cmTRSMRUSkQUr8rk0A6ekwezb06hV2SkRERGpd/QjGAH37hp0CERGRHSK0Yuply5qyfHk1Tvj5Z7j0Upg2bYelSUREJAyhBePNm5O59dZqnNCsGTz+OLz++g5Lk4iISBhCbcD1yCPgnLXNqlR6Ohx0EHz44Q5Pl4iISF0KvTX1McfA999X8eBDDoGvvrIiaxERkQYitGDsnL1OnQrffVfFkzIzwXt1cRIRkQYltGDcvftGzjrLSp+POgrefrsKJx14IPTsCevX7/D0iYiI1JXQgnF6eoRnn4UlS2CPPWwuiMmTKz0JJk6EnByYMaNO0ikiIrKjhd7PuEMH+OAD+O1v4ZRT4Jdf4Nxz4xw8YwYcfjgUFNgEEu+/D4MH12l6RUREalvoDbgAWrWCd96BYcPgvPPg3nvjHJiVZYG4uBg2b4aXXqrLZIqIiOwQCRGMAZo2hddeg5NPhquugptusrZapWRmWo44qSTZjz0GU6bUcUpFRERqV8IEY7A4O2mSFVPfdpsNuBWJxBwweLAVTd92G7z8Muy+OwwfDn/5SzmRW0REpH4Ivc64rORkGD/eiq7vvdcaTj/1FKQEKR08OFpPPGyYRe6XX4YrroCMjNDSLSIiUlMJF4zB+iDffTe0aQM33ggbNsA//1lOrG3a1FpX//KL7fzlF1i9GnbdNZR0i4iI1ERCFVPHcg5uuAEefNDqkocPh7y8OAe2amXrl1wC++0H775bl0kVERHZLgkbjAMXXwzPPmsNqY84AubPt1Exy53xaexY2HlnOPZYuOsu1SOLiEi9kPDBGOCss6wX05dfwpAhNhpmuTM+9ewJn3wCI0bANdfAqafCxo11nl4REZHqqBfBGCyuFhTYHBHeVzDjU7NmVsF8550WtdetCyO5IiIiVVZvgvGSJXDaaTYiZiAtDUaNKmeiCefgT3+Cb7+Frl1tkJBZs+o0vSIiIlVVb4Jx587QsiUUFlrDaecszo4fD7172yiZkydb7nmrFi3s9R//sEkm7rlH9cgiIpJw6k0wBlixAi64AD79FC68EAYNgh9/hHHjYPFiGDnS2m9dd53lpLcaPRpOOAGuvhqOPhr+/GdNNCEiIgmjXgXjV16Bhx6CgQPt9ZVXoEsX64u8ZAm89Rb86lfWkHq33SzuvvwyFKY3h3/9C84/n9z/zOOQsZksP2SkArKIiCSEehWMK5KcbD2aXn8dfvjBejnNnw+/+x107w433OhY2nIA47iZj/k1txZeZ/2lVq1Si2sREQlVgwnGsbp1g1tugaVL4d//hn33teGre959EY9wIRGSeYQLcddfR5POraBHD7jjDhvqS0REpI41yGAcSE62kbvefBM+/xz22gsg2oCrZUs4Zdg6Xut+Keuuu8OC8rhx6g4lIiJ1qkEH41j77w+//jUkJTnS0qKjaE6ethMnzL6JdklrOSAyg+tvTub9Uc+zZcu218jNrWD0LxERkRpqNMEYoq2xP//cWmPvtx+sXQsffgg33uhI27M3d6dcxxGvXUzr1nD4fuv4a+Y7fP7uWoqLLdP88cdxRv8SERGpoYSctWlHeeWV6PpDD0XXhw615c9/hg0bHNOn27TJ779QwPW5w+DD0td55BFbMjJg8+a6SbuIiDRcjSpnXBUtWsBvfgP33Qdf/bQTKz5axMMHPM1uLMYR2XpckvMMGGADfb36qoquRUSk5qoUjJ1zw5xzC51zi51z11Zw3EnOOe+c26/2khiunX7dmws/G8WRA1bi8KSzBUeEPXdaSdLyHO6/33PiiTZCWI8eNob2Aw/AzJllRgNDdc4iIlK+SoupnXPJwEPAkUA2MNM594b3fn6Z41oAlwGf7YiEhm1Fmz5ckPwEY/xjjHfnk9vpSF75aje2kM6X/c9mRu+z+bRoXz7+OJ0XXrBzMjKsW9XgwTYYyRtvROucH3443M8jIiKJoyp1xgcAi733SwCccy8AxwPzyxw3DrgTuLpWU5ggXslqBzMGQNYIHsocAIN3hR+WkjFpEoOff57BL4+H1FT48kuyW+3JjBk2bOeMGTYkdqygzjk11Ybz7NQpnM8kIiKJoSrF1F2BZTHvs0u2beWc2wfY2Xv/Vi2mLfEMHmwDXw8ebO932cXef/21TbZ8/fXQrx/dusGIOTdw77rRfHL7NL7/X4SjjrLgC9atCmzSi86dbcKL44+3HPNbb5VfjJ2bC5ddNkhF3CIiDdB2t6Z2ziUB9wHnVOHYMcAYgA4dOpCVlbW9t08smZkwfToAuy1eTOc33yTlqafo3L49HVpNoqjocNKTiyiIpHLssbkcffQKFi5swaJFLZgzpzn//ndTvLdI3b59Pr17b9i6fPhhB+bN68T55+dw+eVl54yUePLy8hre39kOpmdWfXpm1adnVprzlUwp6JwbDIz13h9d8v46AO/9X0vetwL+B+SVnNIJ+Bk4znsfdxLhPn36+IULF273B0homzbZeJzPP8+Jb/6ezuQyJukJq3PudxivfNoFmjXbeviGDZbB/uKL6PLtt+VfOiXFxuHu08cajiUnx09Gbi6ccgq8+GLjKxLPysoiMzMz7GTUK3pm1adnVn2N8Zk5577w3pfbwLkqOeOZwO7OuZ5ADnAKcFqw03u/Hmgfc7Ms4KqKAnGj0bSpzes4ciSv3HijjX9dXMxDyX+Ar4uhbZp1cD7mGDjmGFr07cvQoY6hQ6OX+O47uOgiG5iksBCSkiwQFxRYFyyAtDTYfXcLzH37ln5t1ar0YCVqOCYikngqrTP23hcBFwPvAguAyd77b5xztzrnjtvRCWwwfvMbi5rJyfZ6//1w8cWQkwNXXgl77AH/+Y8d+/PPkGcFDbvvDr16QXExpKUVAzY986pVFmCffBL++EebMvKbb2z6yLPPhgMPhNatrX76kUcgErFX5yA9HRYsqPq8GOqSJSKyY1Wpzth7PwWYUmbbzXGOzdz+ZDVAgwfbsF5ZWVa3HDQCu/dem/PxnXfg4INt2wMP2DRTQ4bAMcew4rsxXHD8Ro5lPFPc+eQu70T79tC+ffSUQGGhze28cKH1dZ40yWavikTHK6GgwGI/2GQZ3bpVvNx6a81z1o25iFxEpKoa1XCYoRs8OBqEY+2yC5x/fvT98OFW3/z223D11bzC1eAc3jl+k36nDfnlj4o2y46RmmrF0336wHHHwerVMH689XkuKLBBSc4/H7Kzt12+/tqCZ7xmBEGXrORk+w3RtastXbpYq/C0tG3PURG5iEjlFIwT0X772XLXXbBsGVx2Gbz2Gi4SsYg6apQdN2RIdOnf3yqUywgmxxgzxoJybq4dHk9hoR2TnQ3z5sFjj9lrUZFdvkkTS8If/7jtuTvtFA3Qb79tReuBmo7nrZy1iDQGCsaJbued4eqr4Z13iOTnk5SWBmeeaUH6o49g8mQ77swzYcIEW585EwYOhLS0uJNjxJOaCt2723LQQTBnDnz1VTRnfdZZdp01a6y6OycHfvopup6TY4G8VSur+i5ryxbo2NGWTp2iS9n3nTpBmzbbl7MO+ma/+64CuYgkNgXj+qCkvnnpU0+x6+9/Hy3q9t7qm6dPt8pdsCB9wAEWPQ880LLB7drBunVw9NHlF5NXoLyctXNsrbMeODD+uWPGwBNPWIAvLLT5pA891K65fLktixbZa35+xemILSK//XbLhccuHTpY4/VY48bBvHmtVNctIgmv0n7GO0qj6Gdcy6rUL2/jRnjvPQvQH30Es2db0E5KsmbUEyZYRfL++1vRdnkVvbUkmEAjNpDH5tQD3sP69aWD9MKFFggXLrTi7qCIvLjYctfladbMAvPSpeXXe6emWkFCq1bRpWVLey37GC66yIrozz+/ZnXd2xPMw/4h0Bj7f24vPbPqa4zPbHv7GUt90qwZnHCCLQBjx1oWMahvnjTJGoCBBeeBAy0w33hjrX/zV7WI3DnrhtW6tTU8C+Tm2qAnsUXkDz9svzdWrowuq1aVft+9uxWtr1tX+j6FhdHHUlZGhgXmVatKB/LYHPl111nuu1mz6BLv/U031bx4fXsbvW3vDwEV7YvUvtxcgH594u1XzrgeqdEvyRkz4PDDLZqlpcHUqZZdnTkzusyebTNWtG5tzaTffNMCdLD89JONOhLbJasOVDVnXZ4LL7RzUlKKKSpK5qyz7PfG+vW2/PJLdD32/fLl9khWrLDfL85Fu4dv3hy/pXlVdOtmQb9JE3sNluD9yy+XbvQWSEmBO++0nH1ami3Bennb7rvPntOpp8Ldd5e+XzkN8Eu56CJ49FHPBRe4Oi/aD7M0YXvvPWzYOt59t3W9S7eeWd2c6z2cdx48+eR+eD+r3P+FCsb1SI2LdWbM2LZ/c6xIJNoS+9FH4amnLGsZTMjsnO1PS4MHH7Rr9O5tUSJBBYF8771n8uWX+9cokKel2SMIiqq9tyLyjRut59nGjduu5+TA88/b4ysstEfUq5dNoemcnR8smzeXfr9hg9UgVFZ/vj2C4B8swfsvvij/h0ZysrUfTE8v/QOivOWBB+C112DECMvVp6TYkppa/npKSukfB9tTNbC91Qrbe++a/oCp6X29t7/NCy+EZ5+1L/pHH62be9fG+WE8s/x8+8F9+eXwz3/a4Ii33BLdH/v3H2993Dir6ho+HM45x663bl3Fr0uWxKZCwbhBqNM6lvx869M0bpyNr+29fTN36mQRJyMD9trLirkPPRROP71u0lVNNXlm25Mjh/jBvCbnnnce/O1vFtgLCqKv5a3n5tp9PvnE/vnS0mDQIBv8LTU1+gOg7LJli31xLFpkLeC9j5YIpKZG77EjJCeXXxoQ6NnTgnZysi1l1z/9tPwfEUlJ1mAwErH9kci265GI/Wgq73zn7Ddn7P3KLm+8UXowndjPdPHFFf8YueYa6y5Y3rkXXmg/7PLybClvff36+M+sSxerLim7BNUoEybEL4G58krbF28pKrIfm+V97qQk+N3vtn2Osf71r/jP7Mor7W8uPd2WYD14HTXK/s7LS/f115df4hW77MgfuQAtWljhYqtWpV9TUmDWLPv/VVioYNwghNLgoWwx9+OPR7/FvvrK+j4NHWplrGDfgEEz60GD7H/wokUWsOuwiDsQxjPbnmCeCD8EgqL92HMjEfsyi83JB0t2to3u+vHH0R8B++9vOY9mzewLvKjIvkjLrhcW2g+BDz6AxYttW3KyTX6y7752rSAIxAaEYH3jRhu/fc2aaAFPu3Y2PGxQLJ+UZEvsevC+oMCGkc3NjTYU7NgxWvATe6+yy5YtVq2RlxcN6EFJQyRS+vOWF4DKk5JiX+rNm9uza948usS+995qjubPt/ukptrQuYMH2+fatCm6BKU3wZKXZ0GrbEAOxr2P9+Mj2Oe9/WjbuDH6w61FC2s8GVtYVl5oKSqydh2xzyw93dJfVGR/PzUNSS1alG6cWbaRZlKS1dLNmxf9Ott/fzjjDAuaUPrHQ+z62rX2I+Tzz+3c9HT7Whw71kq+WraseLKe4P9WJLKv9/6L8oeh9t6HsvTu3dtL9UybNi2cG3/yifd/+Yu9lhWJeL9xo60XFHg/cqT3ffp475z39v/K1ps08f7DD72/5x7v337b+x9/tHN3sNCeWUhOOMH7iy7yfs4cez3hhOqf+/jjn1f73Asu8D4pyfuMDHu98MLqpXt7zk+Ee6elFVV4bnGx9/n59l9l/Xrv16zx/qyz7L9GerpdY8yYuk93cO4FF9T9vct7ZpGIfY3k5dkzys31fulS7xcu9H7ePO9POsmeWVqavZ5xhvfr1nlfVFR36a7JucH/LWj2jY8TExO30k8SR7xhPMF+PgYdfFNT4YUXbH3TJrjqKqvICiq4Xn0V/v736LktWtgg2bfcYjNXbdpkWZxu3aI/Syur75ZSqjvIS3nnZmVt5Nxzq3duef3R6+r8RLj33nvP3to2oTxBk4vYLnQbNliOSc8sus85+xpJTS01u+xWkci2z6xVq7pNd03ODf5vPfzwxrjjD6qYuh6pd/3yyhZxv/++laXNn2/LN9/YcsMNdtx779nAJEGQ7tAB3n3X/gcG51czINe7Z5YA9MyqT8+s+hrjM1M/YwlHvJmqhg6l1KTNgX79rJIyCNLTpkVbbBQUWEumc8+NzoQRTNq8zz47dPASEZEdTcFYdqyKirjL2nlnK4MKzJgBhx1mATktzYb3zM+3XPW//x1tjrpqlTUae+YZ+O9/o8F60ya6v/eetbZQEbeIJDAFY0lcgwdbM9vYnPWVV9q+wkL4/ntrStu+vW1buhRef92Cc4meYJ0K33/fOvytXm1F5b16Wb+Z1NS6/UwiIuVQMJbEFi9nnZpq/U96945uGzvWlp9/tnroxx7DBY3HsrKsL8i770aPT062Llf/+Y+9f+UVy4H36mWtNT75RA3HRKROKBhLw9O2rQ1k/eyz0WknMzPh2mst17x4seWoFy+2TpuBq66y3HaslBSbdGPwYCsa32kn2HVXy41XNrakiEgVKRhLwxRv2slgzsWDDtr2nM8/twB9333w0kvWJau42HLVBx5owwsFQ1E1b25BefRouPRSO/btt21bjx7w5ZfqkiUiVaZgLA3X4MH8mJ/PrlUNhsEkzZdfbpNlBF2ygu4Xs2dbvXPskpFh+1assHEny0pLs6A8YIA1LuvRw6aVCs4TEUHBWGRb8bpk7bmnLeVp08bqmJcssVbdU6fa9qIiu05qqvWhDnTqZIH59tutxfjKlTZbQ48eNsbip58qVy3SiCgYi5SnOl2yINp9avBgK6r+739L56z79rW656VLbfnhB3sNcsj//a8NTB3LOXj6aTj7bCs+nzPHctXdu1tRe1L5Q9yKSP2jYCxS2+LlrIcMsaU8hx1mMy088IBNbROM7P3117Z/yhS47LLo8enp1i/7/fctOH/2mR3bvbsNKbpwIRx1lHLWIvWEgrHIjlDdnHWrVnDwwZbb/fe/o7nqILc8apSNWvbjj6WXtm1t/0svwT33lL7m2LE2illmpo0L/u23FsC7dYu+pqeXPmfGDLpPnKiBUkTqmIKxSCKJl6tu0cKmpBw0qPzz/vIX+MMf7PXJJ208b+dsFLPMTGuQ9tRTpc9p08b6ZIO1IJ8xA15/nZ5FRfDcczBp0rZF5yKyQygYiySa6uaqwRqI9ehhOejnn9+2JfiTT1oReHY2LFtmy5Yt0fO//NJy5IWFOLBhRy+6KBqMR4+2PtrdukWXvn3hgAOi19AMWyI1pmAs0pDEy1mDzUkXjNtd1nPPWfA9/HB8fj4uNdUGSYn144/WYnzNGnt/7LHw1lu23quXtST33kY2O+MMOPlkOwbgp59sFi4NPypSLgVjkYamJjnr4Lz33+f7sgOlgOWsA5s3Q06OFYUHOnaE//3P1ouLYcIEq3c+9lh73727Hd+hA3TpYstpp8Hpp9v+KVNs3PBFi+yceA3dRBooBWMRiarKQClNmlhOONY995Seu/q992xqS7Bg+/DDljuOXVavtv0rVsBxx0WvdccdVp991102Zebq1XDvvdC5s/XP7tzZlm7dol3DVEQu9ZyCsYhsv4qKx9PSYMyY+Oe2a2dF5I8+Gm141quX1YGDFY/fc090yszAhAlw5pk2yMro0XZuSooF8AMPtK5dXbrYec5Z8blIglIwFpHaUdPi8fR0q2N++ulozvr++6PX2mcfa1D288+Qm2sjlOXmwq9/bfs//zxaZF5UZEH90Udt+s0uXWw2rtNOs4FSgpx1p05w000W8Jcts9bmixfDsGFwxBGaBETqnIKxiISvopw1WP/rYOzw/v1L7wtyx0Egf/NNC7KdOtn+vn3huutKB/I5c6IN1O6+Gx580Nbvu89y15062ZCkXbtafXZWltWLBxONdOxo6UhOVt9sqRUKxiKSGLaz4VncQD5ggC3xNGtmwT4oIj/oIBvStE0b2z9zpuXUgxm7Avn5lisfOtT6Zj/1lN1/jz0s93399Xbc999bK/OOHe1esVTXLSUUjEWk/qtpIAdrPBYE27Q0a0AWe61bboGbb4ZffrEJPVautEZlwYxcxcXWNzsSgblzbXav1NRoML7qKisqBwvGQa76mmus0Vt+vuWwb7zRRmELitM7dNiOByL1TUIF48LCQrKzs9kSOxiBbNWqVSsWLFhQZ/fLyMigW7dupKpvqDRkleWswXLMrVrZsvvu0e2ZmZCRQSQ/n6T0dHjjDTu/sDB6zFVXwfDh1mp85Up7bdHC7ldQYEE8ErGgH9h/f8t1A5x0kg24stNOFqA7dLCR2E480XLWL70Ehx5q9d0pCfWVLtWQUP9y2dnZtGjRgh49euDUgGIbGzZsoEWLFnVyL+89a9asITs7m549e9bJPUVCs51F5EvL9s2O/QEb79ozZljuuqDAjn/ySaujXrnSuo8FOna0gVYWLIAPP7T144+3ovDDD7d+3/fdZ8e2aWPB+pRT4M9/tm233gotW9r29u3ttXt3+O47FZEnkIQKxlu2bFEgThDOOdq1a8eqVavCTopIYqtK3+w451WaIwfrox2ruNgC8IMPRuuxk5Isd9y3r+Wi27e37YWFMG7ctt3CTjkFXn89mjPv29cavQUB+7e/tTTl58OsWdHtrVtHp+5UfXetSqhgDCgQJxD9W4jsYDXJkScnQ/PmFgSDnHVamgXdstdKTbWAum6d1XOvWmXL++/becXFVgRfVGQ58m++seO6dLHr//hjtAtZcO927eDCC21Qlvx8O/+006zovF07W/bf33L0wfXLzr2tFujbSLhgLCIiVVDVnHVSkk212bYt9O5t2zp2tGLxIJA/+2zp84N+2507wzvvRAN58JqbG81VA0ycaOObB15+2eq0338fjjnG7h0E6qQkmDmTnoWFNqnJZZfZhCPB/rZtrX48Xv13A82RKxiHpKioiBQ1thCR7bGjuoMFOdnmzeHoo7c9f8YMC75BMJ86Ffbc0+qzV6+ODpe6yy7WqjzYvmYNzJ9vs4NFInb+nXdue/0vv7Sc9sSJNhRqEKgLC62RnPd23+eft7m527WzYvQWLSofsCVBg7miQTn+7//+j2XLlrFlyxYuu+wyxowZwzvvvMP1119PcXEx7du35/333ycvL49LLrmEWbNm4Zzjlltu4aSTTqJ58+bk5eUB8NJLL/Hmm2/yzDPPcM4555CRkcGXX37JwQcfzCmnnMJll13Gli1baNKkCU8//TR9+vShuLiYa665hnfeeYekpCTOO+889txzT+677z7efPNNAP7zn//w8MMP8+qrr4b5qESkvtqe7mDxgnmrVtZHO9CnjxWfx5oxAw4/PNoCfdIkq69es8ZGWVuzJjoUaosWVmS+Zg388INNARrUfxcUwD/+AdOmRa+dmmqB+bvv7IfEc8/BRx9ZoG7Xzorr77rLis/T0mza0CFDbD1kiR2Mg7lYY518so1ju2lTdHq2WOecY8vq1fC735Xel5VVpds+9dRTtG3bls2bN7P//vtz/PHHc9555zF9+nR69uzJzyUTso8bN45WrVoxb948ANauXVvptbOzs/nkk09ITk7ml19+4aOPPiIlJYWpU6dy/fXX8/LLLzN+/HiWLl3KnDlzSElJ4eeff6ZNmzZccMEFrFq1ig4dOvD000/z+9//vkqfR0Sk1tV2C/TyHHdc6UlESgL51hz5RRfBFVdEc93BazC4yqJFlpNes2bbRmwFBXDllfDVV3Z8mza29OxpjdvAxj9ftsyKztu0seL577+HU0+t9Vx1YgfjkDzwwANbc5zLli1j/PjxDB06dGsXn7Zt2wIwdepUXnjhha3ntQlG7KnAiBEjSC4ZsH79+vWcffbZfPfddzjnKCzpmzh16lQuuOCCrcXYwf1OOeUUnn/+eUaNGsWMGTOYMGFCLX1iEZE6tKNboAfGjbPFexu05b33bPjUoiIL5mecYZm2tWtt+flnaNo0ev4LL8Dbb2973SeesHRcd50Vuwd13e3awX772SAxYHXnkYhtz86mK3SKl9TEDsYV5WSbNq14f/v2Vc4Jl75lFlOnTmXGjBk0bdqUzMxMBg0axLffflvla8S2Qi47gEmzmOHwbrrpJg499FBeffVVli5dSmZ5JQExzjjjDE499VQyMjIYMWKE6pxFpPGpSY48GLRlxAiberOqwXzKFGsxvnat1W0/8IAF14ICu8YJJ1i3sKB4/ccf7T6Bq66CpUu3vu0EXePdKinejsZq/fr1tGnThqZNm/Ltt9/y6aefsmXLFqZPn873338PsLWY+sgjj+Shhx7aem5QTN2xY0cWLFhAJBKpsE53/fr1dO1q/zbPPPPM1u1HHnkkjz32GEUlxSrB/Tp37kyXLl247bbbGDVqVO19aBGRxmLwYMvRVjWgp6fb8KQnn2zrycmWq87MtJbgjz4KkydbTnnOnNKtyj/5xIZIPffcbbt3laFgXMawYcMoKiqiX79+XHvttfzqV7+iQ4cOjB8/nhNPPJGBAwcycuRIAG688UbWrl3LXnvtxcCBA5lW0pDgjjvuYPjw4Rx00EF07tw57r3+9Kc/cd1117H33ntvDbwA5557Lt27d2fAgAEMHDiQSZMmbd13+umns/POO9OvX78d9ARERGQbQRH5uHH2WpVg3rmzjUP++99DejoefLxDnfdx90UPcm4YcD+QDDzhvb+jzP4rgHOBImAV8Hvv/Q8VXbNPnz5+4cKFpbYtWLBAQaYCGzZs2Bq8R48eXSf3rO//JllZWZUW/0tpembVp2dWfY3umc2YQbeDDsrJ9r5bebsrzRk755KBh4BjgD2AU51ze5Q57EtgP+/9AOAl4K7tS7WUZ+jQocydO5czzjgj7KSIiEh1DB5MDiyPt7sqLYAOABZ775cAOOdeAI4H5gcHeO9jOnrxKaBosQNMnz69ziaKEBGRulOVYNwVWBbzPhs4sILjRwPltAUH59wYYAxAhw4dyCrT2rlVq1Zs2LChCklqnIqLi+v8+WzZsmWbf6f6JC8vr16nPwx6ZtWnZ1Z9emal1WrfGOfcGcB+wCHl7ffejwfGg9UZl60vWLBggXJ+FajLKRQDGRkZ7L333nV6z9rU6OqlaoGeWfXpmVWfnllpVQnGOcDOMe+7lWwrxTl3BHADcIj3Pr92kiciItLwVaVr00xgd+dcT+dcGnAK8EbsAc65vYHHgOO89ytrP5kiIiINV6XB2HtfBFwMvAssACZ7779xzt3qnAsGDb0baA78yzk3xzn3RpzLJbzmzZuHnQQREWlkqlRn7L2fAkwps+3mmPUjajldIiIijUb9H4Frxgz461/ttRZ577n66qvZa6+96N+/Py+++CIAubm5DB06lEGDBrHXXnvx0UcfUVxczDnnnLP12L/97W+1mhYREWnYEnumgcqmUDz4YBv3MxKxcT8HDLCxQrdzCkWAV155hTlz5vDVV1+xevVq9t9/f4YOHcqkSZM4+uijueGGGyguLmbTpk3MmTOHnJwcvv76awDWrVtX008sIiKNUP3OGa9fb4EY7HX9+lq79Mcff8ypp55KcnIyHTt25JBDDmHmzJnsv//+PP3004wdO5Z58+bRokULdt11V5YsWcIll1zCO++8Q8uWLWstHSIi0vAlds64sikUJ04sPdH0xInRwbtrOIViZYYOHcr06dN56623OOecc7jiiis466yz+Oqrr3j33Xd59NFHmTx5Mk899VSt31tERBqm+p0zrsksGlU0ZMgQXnzxRYqLi1m1ahXTp0/ngAMO4IcffqBjx46cd955nHvuucyePZvVq1cTiUQ46aSTuO2225g9e3atpUNERBq+xM4ZV0VNJpqughNOOIEZM2YwcOBAnHPcdddddOrUiWeffZa7776b1NRUmjdvzoQJE8jJyWHUqFFESorM//rXv9Z6ekREpOGq/8G4luXl5QHgnOPuu+/m7rvvLrX/7LPP5uyzz97mPOWGRUSkpup3MbWIiEgDoGAsIiISMgVjERGRkCkYi4iIhEzBWEREJGQKxiIiIiFTMBYREQmZgvF20NzHIiJSGxSMG4CioqKwkyAiItshYUfg+uMfYc6c2r3moEHw97/H33/ttdey884784c//AGAsWPHkpKSwrRp01i7di2FhYXcdtttHH/88ZXeKy8vj+OPP77c8yZMmMA999yDc44BAwbw3HPPsWLFCi644AKWLFkCwCOPPEKXLl0YPnz41qkZH3jgAQoLCxk7diyZmZkMGjRo6+xSvXv35rbbbqOgoIB27doxceJEOnbsSF5eHpdccgmzZs3COcctt9zC+vXrmTt3Ln8veRiPP/448+fP1zzMIiIhSdhgHIaRI0fyxz/+cWswnjx5Mu+++y6XXnopLVu2ZPXq1fzqV7/iuOOOwzlX4bUyMjJ49dVXtzlv/vz53HbbbXzyySe0b9+en3/+GYBLL72UQw45hFdffZXi4mLy8vJYu3ZthfcoKChg1qxZAKxdu5ZPP/0U5xxPPPEEd911F/feey/jxo2jVatWzJs3b+txqamp3H777VvH2H766ad57LHHtvfxiYhIDSVsMK4oB7uj7L333qxcuZKffvqJVatW0aZNGzp16sTll1/O9OnTSUpKIicnhxUrVtCpU6cKr+W95/rrr9/mvA8++IARI0bQvn17ANq2bQvABx98wIQJEwBITk6mVatWlQbjkSNHbl3Pzs5m5MiR5ObmUlBQQM+ePQGYOnUqL7zwwtbj2rRpA8Bhhx3Gm2++Sb9+/SgsLKR///7VfFoiIlJbEjYYh2XEiBG89NJLLF++nJEjRzJx4kRWrVrFF198QWpqKj169GDLli2VXqem58VKSUnZOhMUwJYtW0hOTt76vlmzZlvXL7nkEq644gqOO+44srKyGDt2bIXXPvfcc/nLX/5C3759GTVqVLXSJSIitUsNuMoYOXIkL7zwAi+99BIjRoxg/fr17LTTTqSmpjJt2jR++OGHKl0n3nmHHXYY//rXv1izZg3A1mLqww8/nEceeQSA4uJi1q9fT8eOHVm5ciVr1qwhPz+fd955p8L7de3aFYBnn3126/YjjzyShx56aOv7ILd94IEHsmzZMiZNmsSpp55a1ccjIiI7gIJxGXvuuScbNmyga9eudO7cmdNPP51Zs2bRv39/JkyYQN++fat0nXjn7bnnntxwww0ccsghDBw4kCuuuAKA+++/n2nTptG/f3/23Xdf5s+fT2pqKjfffDMHHHAARx55JL179457v7FjxzJixAj23XffrUXgADfeeCNr165lr732YuDAgUybNm3rvpNPPpmDDz54a9G1iIiEw3nvQ7lxnz59/MKFC0ttW7BgAf369QslPfXBhg0baNGiRa1db/jw4Vx++eUcfvjhcY+p7/8mWVlZZGZmhp2MekXPrPr0zKqvMT4z59wX3vv9ytunnHEjtG7dOnr37k2TJk0qDMQiIlI31IBrO82bN48zzzyz1Lb09HQ+++yzkFJUudatW7No0aKwkyEiIiUUjLdT//79mVPbo5OIiEijomJqERGRkCkYi4iIhEzBWEREJGQKxiIiIiGr98E4NxcOOQSWL6/7e1c0n/HSpUvZa6+96jA1IiJSX9X7YDxuHHz8Mdx6a9gpERERqZmE7dpU2XzGH30EMXMo8MgjtiQlwZAh5Z9Tl/MZx9qyZQsXXnghs2bNIiUlhfvuu49DDz2Ub775hlGjRlFQUEAkEuHll1+mS5cunHzyyWRnZ1NcXMxNN91UanYmERFpeBI2GFfmgANgyRJYvdqCclIStG8Pu+1W82vW5nzGsR566CGcc8ybN49vv/2Wo446ikWLFvHoo49y2WWXcfrpp1NQUEBxcTFTpkyhS5cuvPXWW4BNACEiIg1bwgbjqsxnfOGFMH48ZGRAQQGcdBI8/HDN71mb8xnH+vjjj7nkkksA6Nu3L7vssguLFi1i8ODB3H777WRnZ3PiiSey++67079/f6688kquueYahg8fzpB42XwREWkw6nWd8YoVcMEF8Omn9lobjbiC+YxffPHFbeYznjNnDh07dqz2vMTxnHbaabzxxhs0adKEY489lg8++IDevXsze/Zs+vfvz4033sitqgwXEWnwEjZnXBWvvBJdj5myd7uMHDmS8847j9WrV/Phhx8yefLkGs1nHGvIkCFMnDiRww47jEWLFvHjjz/Sp08flixZwq677sqll17Kjz/+yNy5c+nbty9t27bljDPOoHXr1jzxxBO188FERCRh1etgvCOUN5/xb3/7W/r3789+++1X5fmMY1100UVceOGF9O/fn5SUFJ555hnS09OZPHkyzz33HKmpqXTq1Inrr7+emTNncvXVV5OUlERqaiqPPPLIDviUIiKSSBSMyzFv3ryt6+3bt2fGjBnlHpeXlxf3Gj169ODrr78GICMjg6effnqbY6699lquvfbaUtuOPvpojj766JokW0RE6ql6XWcsIiLSEChnvJ3q43zGIiKSWBSMt5PmMxYRke2VcMXU3vuwkyAl9G8hIlI3EioYZ2RksGbNGgWBBOC9Z82aNWRkZISdFBGRBi+hiqm7detGdnY2q1atCjspCWnLli11GhwzMjLo1q1bnd1PRKSxqlIwds4NA+4HkoEnvPd3lNmfDkwA9gXWACO990urm5jU1FR69uxZ3dMajaysLPbee++wkyEiIrWs0mJq51wy8BBwDLAHcKpzbo8yh40G1nrvewF/A+6s7YSKiIg0VFWpMz4AWOy9X+K9LwBeAMrOIXg88GzJ+kvA4a460xqJiIg0YlUJxl2BZTHvs0u2lXuM974IWA+0q40EioiINHR12oDLOTcGGFPyNt8593Vd3r8BaA+sDjsR9YyeWfXpmVWfnln1NcZntku8HVUJxjnAzjHvu5VsK++YbOdcCtAKa8hVivd+PDAewDk3y3u/XxXuLyX0zKpPz6z69MyqT8+s+vTMSqtKMfVMYHfnXE/nXBpwCvBGmWPeAM4uWf8d8IFXZ2EREZEqqTRn7L0vcs5dDLyLdW16ynv/jXPuVmCW9/4N4EngOefcYuBnLGCLiIhIFVSpzth7PwWYUmbbzTHrW4AR1bz3+GoeL3pmNaFnVn16ZtWnZ1Z9emYxnEqTRUREwpVQY1OLiIg0RqEEY+fcMOfcQufcYufctWGkob5xzi11zs1zzs1xzs0KOz2JyDn3lHNuZWyXOedcW+fcf5xz35W8tgkzjYkmzjMb65zLKflbm+OcOzbMNCYS59zOzrlpzrn5zrlvnHOXlWzX31kcFTwz/Z3FqPNi6pLhNRcBR2IDiMwETvXez6/ThNQzzrmlwH7e+8bWL6/KnHNDgTxggvd+r5JtdwE/e+/vKPnh18Z7f02Y6UwkcZ7ZWCDPe39PmGlLRM65zkBn7/1s51wL4Avg/4Bz0N9ZuSp4Ziejv7OtwsgZV2V4TZFq895Px1rzx4odqvVZ7EtASsR5ZhKH9z7Xez+7ZH0DsAAbgVB/Z3FU8MwkRhjBuCrDa8q2PPCec+6LkpHMpGo6eu9zS9aXAx3DTEw9crFzbm5JMbaKXMvhnOsB7A18hv7OqqTMMwP9nW2lBlz1x6+99/tgs2f9oaR4UaqhZCAadR+o3CPAbsAgIBe4N9TUJCDnXHPgZeCP3vtfYvfp76x85Twz/Z3FCCMYV2V4TSnDe59T8roSeBUr7pfKrSipswrqrlaGnJ6E571f4b0v9t5HgMfR31opzrlULKhM9N6/UrJZf2cVKO+Z6e+stDCCcVWG15QYzrlmJQ0fcM41A44CNMlG1cQO1Xo28HqIaakXgqBS4gT0t7ZVydSwTwILvPf3xezS31kc8Z6Z/s5KC2XQj5Im7H8nOrzm7XWeiHrEObcrlhsGGzVtkp7Ztpxz/wQysdlgVgC3AK8Bk4HuwA/Ayd57NVgqEeeZZWJFhx5YCpwfUx/aqDnnfg18BMwDIiWbr8fqQPV3Vo4Kntmp6O9sK43AJSIiEjI14BIREQmZgrGIiEjIFIxFRERCpmAsIiISMgVjERGRkCkYi9RTzrnimBlv5tTmDGjOuR6xMzmJyI6VEnYCRKTGNnvvB4WdCBHZfsoZizQwJXNf31Uy//XnzrleJdt7OOc+KBmY/33nXPeS7R2dc686574qWQ4quVSyc+7xkjlo33PONQntQ4k0cArGIvVXkzLF1CNj9q333vcH/oGNdgfwIPCs934AMBF4oGT7A8CH3vuBwD7ANyXbdwce8t7vCawDTtqhn0akEdMIXCL1lHMuz3vfvJztS4HDvPdLSgboX+69b+ecW41N8l5Ysj3Xe9/eObcK6Oa9z4+5Rg/gP9773UveXwOkeu9vq4OPJtLoKGcs0jD5OOvVkR+zXozamIjsMArGIg3TyJjXGSXrn2CzpAGcjg3eD/A+cCGAcy7ZOdeqrhIpIka/dEXqrybOuTkx79/x3gfdm9o45+ZiudtTS7ZdAjztnLsaWAWMKtl+GTDeOTcaywFfiE32LiJ1RHXGIg1MSZ3xft771WGnRUSqRsXUIiIiIVPOWEREJGTKGYuIiIRMwVhERCRkCsYiIiIhUzAWEREJmYKxiIhIyBSMRUREQvb/UYYr+x56JD8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 29],\n",
    "    ylim=[0, 1],\n",
    "    grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8743 - loss: 0.3708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3711923062801361, 0.8730000257492065]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.02, 0.  , 0.76],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you only care about the class with the highest estimated probability (even if that probability is quite low), then you can use the argmax() method to get the highest probability class index for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let’s switch back to the California housing problem and tackle it using the same MLP as earlier, with 3 hidden layers composed of 50 neurons each, but this time building it with Keras. Using the sequential API to build, train, evaluate, and use a regression MLP is quite similar to what we did for classification. The main differences in the following code example are the fact that the output layer has a single neuron (since we only want to predict a single value) and it uses no activation function, the loss function is the mean squared error, the metric is the RMSE, and we’re using an Adam optimizer like Scikit-Learn’s MLPRegressor did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - RootMeanSquaredError: 1.1557 - loss: 1.4279 - val_RootMeanSquaredError: 0.7325 - val_loss: 0.5366\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - RootMeanSquaredError: 0.6355 - loss: 0.4043 - val_RootMeanSquaredError: 0.6402 - val_loss: 0.4099\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.6037 - loss: 0.3648 - val_RootMeanSquaredError: 0.5753 - val_loss: 0.3310\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.5862 - loss: 0.3438 - val_RootMeanSquaredError: 0.7954 - val_loss: 0.6327\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5748 - loss: 0.3306 - val_RootMeanSquaredError: 0.5597 - val_loss: 0.3133\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5650 - loss: 0.3194 - val_RootMeanSquaredError: 0.9203 - val_loss: 0.8469\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5592 - loss: 0.3128 - val_RootMeanSquaredError: 0.9108 - val_loss: 0.8296\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - RootMeanSquaredError: 0.5540 - loss: 0.3070 - val_RootMeanSquaredError: 1.2802 - val_loss: 1.6390\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - RootMeanSquaredError: 0.5498 - loss: 0.3023 - val_RootMeanSquaredError: 1.8206 - val_loss: 3.3146\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5488 - loss: 0.3012 - val_RootMeanSquaredError: 1.1273 - val_loss: 1.2708\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - RootMeanSquaredError: 0.5446 - loss: 0.2967 - val_RootMeanSquaredError: 1.3587 - val_loss: 1.8460\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5406 - loss: 0.2923 - val_RootMeanSquaredError: 1.0505 - val_loss: 1.1035\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - RootMeanSquaredError: 0.5335 - loss: 0.2847 - val_RootMeanSquaredError: 0.9416 - val_loss: 0.8866\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5295 - loss: 0.2804 - val_RootMeanSquaredError: 0.7125 - val_loss: 0.5077\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5257 - loss: 0.2764 - val_RootMeanSquaredError: 0.5778 - val_loss: 0.3339\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5212 - loss: 0.2717 - val_RootMeanSquaredError: 0.5272 - val_loss: 0.2780\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5192 - loss: 0.2696 - val_RootMeanSquaredError: 0.5579 - val_loss: 0.3112\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5171 - loss: 0.2675 - val_RootMeanSquaredError: 0.5273 - val_loss: 0.2780\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5145 - loss: 0.2648 - val_RootMeanSquaredError: 0.5602 - val_loss: 0.3138\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5124 - loss: 0.2627 - val_RootMeanSquaredError: 0.5213 - val_loss: 0.2717\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5308 - loss: 0.2820\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API\n",
    "\n",
    "* It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.\n",
    "\n",
    "* Let’s build such a neural network to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_],\n",
    "    outputs=[output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path ? In this case, one solution is to use multiple inputs. For example, suppose we want to send five features through the wide path (features 0 to 4), and six features through the deep path (features 2 to 7). We can do this as follows.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5]) # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6]) # features 2 to 7\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can compile the model as usual, but when we call the fit() method, instead of passing a single input matrix X_train, we must pass a pair of matrices (X_train_wide, X_train_deep), one per input. The same is true for X_valid, and also for X_test and X_new when you call evaluate() or predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - RootMeanSquaredError: 1.7301 - loss: 3.1069 - val_RootMeanSquaredError: 1.8694 - val_loss: 3.4946\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - RootMeanSquaredError: 0.7862 - loss: 0.6185 - val_RootMeanSquaredError: 0.8385 - val_loss: 0.7030\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.7088 - loss: 0.5027 - val_RootMeanSquaredError: 0.6630 - val_loss: 0.4395\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.6738 - loss: 0.4542 - val_RootMeanSquaredError: 0.6272 - val_loss: 0.3933\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - RootMeanSquaredError: 0.6477 - loss: 0.4196 - val_RootMeanSquaredError: 0.6129 - val_loss: 0.3757\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.6275 - loss: 0.3938 - val_RootMeanSquaredError: 0.5980 - val_loss: 0.3576\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.6142 - loss: 0.3774 - val_RootMeanSquaredError: 0.6714 - val_loss: 0.4507\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.6056 - loss: 0.3668 - val_RootMeanSquaredError: 0.6252 - val_loss: 0.3908\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5990 - loss: 0.3589 - val_RootMeanSquaredError: 1.1021 - val_loss: 1.2147\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5965 - loss: 0.3559 - val_RootMeanSquaredError: 1.3325 - val_loss: 1.7756\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5958 - loss: 0.3550 - val_RootMeanSquaredError: 1.4397 - val_loss: 2.0727\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5947 - loss: 0.3538 - val_RootMeanSquaredError: 1.2098 - val_loss: 1.4635\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - RootMeanSquaredError: 0.5885 - loss: 0.3463 - val_RootMeanSquaredError: 0.7561 - val_loss: 0.5716\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5836 - loss: 0.3406 - val_RootMeanSquaredError: 0.7862 - val_loss: 0.6181\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5818 - loss: 0.3385 - val_RootMeanSquaredError: 0.7661 - val_loss: 0.5869\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5807 - loss: 0.3372 - val_RootMeanSquaredError: 0.7846 - val_loss: 0.6156\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5789 - loss: 0.3352 - val_RootMeanSquaredError: 0.7874 - val_loss: 0.6200\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5771 - loss: 0.3331 - val_RootMeanSquaredError: 0.8038 - val_loss: 0.6460\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5758 - loss: 0.3317 - val_RootMeanSquaredError: 0.7141 - val_loss: 0.5100\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5752 - loss: 0.3309 - val_RootMeanSquaredError: 0.8103 - val_loss: 0.6565\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - RootMeanSquaredError: 0.5807 - loss: 0.3373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "history = model.fit((X_train_wide,X_train_deep), y_train, epochs=20, validation_data=((X_valid_wide,X_valid_deep),y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_wide, input_deep], \n",
    "    outputs=[output, aux_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each output will need its own loss function. Therefore, when we compile the model, we should pass a list of losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    loss=(\"mse\", \"mse\"),\n",
    "    loss_weights=(0.9, 0.1),\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now when we train the model, we need to provide labels for each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - dense_2_RootMeanSquaredError: 1.5207 - dense_2_loss: 2.3736 - dense_3_RootMeanSquaredError: 1.9610 - dense_3_loss: 3.9498 - loss: 2.5313 - val_dense_2_RootMeanSquaredError: 0.7884 - val_dense_2_loss: 0.6214 - val_dense_3_RootMeanSquaredError: 2.8028 - val_dense_3_loss: 7.8522 - val_loss: 1.3450\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.7666 - dense_2_loss: 0.5884 - dense_3_RootMeanSquaredError: 0.9767 - dense_3_loss: 0.9547 - loss: 0.6250 - val_dense_2_RootMeanSquaredError: 0.6772 - val_dense_2_loss: 0.4585 - val_dense_3_RootMeanSquaredError: 1.9264 - val_dense_3_loss: 3.7091 - val_loss: 0.7838\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.6947 - dense_2_loss: 0.4829 - dense_3_RootMeanSquaredError: 0.8297 - dense_3_loss: 0.6886 - loss: 0.5035 - val_dense_2_RootMeanSquaredError: 0.6677 - val_dense_2_loss: 0.4458 - val_dense_3_RootMeanSquaredError: 1.3704 - val_dense_3_loss: 1.8771 - val_loss: 0.5891\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.6626 - dense_2_loss: 0.4393 - dense_3_RootMeanSquaredError: 0.7759 - dense_3_loss: 0.6022 - loss: 0.4556 - val_dense_2_RootMeanSquaredError: 0.6154 - val_dense_2_loss: 0.3786 - val_dense_3_RootMeanSquaredError: 1.0691 - val_dense_3_loss: 1.1425 - val_loss: 0.4551\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - dense_2_RootMeanSquaredError: 0.6433 - dense_2_loss: 0.4140 - dense_3_RootMeanSquaredError: 0.7487 - dense_3_loss: 0.5607 - loss: 0.4287 - val_dense_2_RootMeanSquaredError: 0.6542 - val_dense_2_loss: 0.4278 - val_dense_3_RootMeanSquaredError: 0.9602 - val_dense_3_loss: 0.9216 - val_loss: 0.4773\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - dense_2_RootMeanSquaredError: 0.6292 - dense_2_loss: 0.3961 - dense_3_RootMeanSquaredError: 0.7288 - dense_3_loss: 0.5313 - loss: 0.4096 - val_dense_2_RootMeanSquaredError: 0.6462 - val_dense_2_loss: 0.4175 - val_dense_3_RootMeanSquaredError: 0.8354 - val_dense_3_loss: 0.6978 - val_loss: 0.4457\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6193 - dense_2_loss: 0.3838 - dense_3_RootMeanSquaredError: 0.7132 - dense_3_loss: 0.5088 - loss: 0.3963 - val_dense_2_RootMeanSquaredError: 0.8942 - val_dense_2_loss: 0.7994 - val_dense_3_RootMeanSquaredError: 0.7440 - val_dense_3_loss: 0.5534 - val_loss: 0.7751\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - dense_2_RootMeanSquaredError: 0.6124 - dense_2_loss: 0.3752 - dense_3_RootMeanSquaredError: 0.6989 - dense_3_loss: 0.4886 - loss: 0.3866 - val_dense_2_RootMeanSquaredError: 1.2381 - val_dense_2_loss: 1.5323 - val_dense_3_RootMeanSquaredError: 0.8141 - val_dense_3_loss: 0.6626 - val_loss: 1.4460\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - dense_2_RootMeanSquaredError: 0.6082 - dense_2_loss: 0.3701 - dense_3_RootMeanSquaredError: 0.6860 - dense_3_loss: 0.4707 - loss: 0.3801 - val_dense_2_RootMeanSquaredError: 1.5083 - val_dense_2_loss: 2.2738 - val_dense_3_RootMeanSquaredError: 0.6625 - val_dense_3_loss: 0.4389 - val_loss: 2.0912\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - dense_2_RootMeanSquaredError: 0.6048 - dense_2_loss: 0.3659 - dense_3_RootMeanSquaredError: 0.6747 - dense_3_loss: 0.4553 - loss: 0.3749 - val_dense_2_RootMeanSquaredError: 2.1644 - val_dense_2_loss: 4.6823 - val_dense_3_RootMeanSquaredError: 1.7090 - val_dense_3_loss: 2.9192 - val_loss: 4.5082\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6076 - dense_2_loss: 0.3693 - dense_3_RootMeanSquaredError: 0.6700 - dense_3_loss: 0.4490 - loss: 0.3773 - val_dense_2_RootMeanSquaredError: 1.7252 - val_dense_2_loss: 2.9749 - val_dense_3_RootMeanSquaredError: 0.7611 - val_dense_3_loss: 0.5791 - val_loss: 2.7367\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6010 - dense_2_loss: 0.3613 - dense_3_RootMeanSquaredError: 0.6573 - dense_3_loss: 0.4321 - loss: 0.3683 - val_dense_2_RootMeanSquaredError: 1.3002 - val_dense_2_loss: 1.6898 - val_dense_3_RootMeanSquaredError: 0.6390 - val_dense_3_loss: 0.4083 - val_loss: 1.5623\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - dense_2_RootMeanSquaredError: 0.5932 - dense_2_loss: 0.3520 - dense_3_RootMeanSquaredError: 0.6491 - dense_3_loss: 0.4214 - loss: 0.3590 - val_dense_2_RootMeanSquaredError: 0.9236 - val_dense_2_loss: 0.8526 - val_dense_3_RootMeanSquaredError: 0.6358 - val_dense_3_loss: 0.4042 - val_loss: 0.8081\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.5878 - dense_2_loss: 0.3457 - dense_3_RootMeanSquaredError: 0.6431 - dense_3_loss: 0.4137 - loss: 0.3525 - val_dense_2_RootMeanSquaredError: 0.8310 - val_dense_2_loss: 0.6903 - val_dense_3_RootMeanSquaredError: 0.7749 - val_dense_3_loss: 0.6003 - val_loss: 0.6815\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - dense_2_RootMeanSquaredError: 0.5846 - dense_2_loss: 0.3418 - dense_3_RootMeanSquaredError: 0.6379 - dense_3_loss: 0.4071 - loss: 0.3483 - val_dense_2_RootMeanSquaredError: 0.7516 - val_dense_2_loss: 0.5647 - val_dense_3_RootMeanSquaredError: 0.6419 - val_dense_3_loss: 0.4120 - val_loss: 0.5496\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - dense_2_RootMeanSquaredError: 0.5819 - dense_2_loss: 0.3387 - dense_3_RootMeanSquaredError: 0.6328 - dense_3_loss: 0.4006 - loss: 0.3449 - val_dense_2_RootMeanSquaredError: 0.8883 - val_dense_2_loss: 0.7887 - val_dense_3_RootMeanSquaredError: 0.8249 - val_dense_3_loss: 0.6803 - val_loss: 0.7782\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - dense_2_RootMeanSquaredError: 0.5804 - dense_2_loss: 0.3370 - dense_3_RootMeanSquaredError: 0.6300 - dense_3_loss: 0.3970 - loss: 0.3430 - val_dense_2_RootMeanSquaredError: 1.0219 - val_dense_2_loss: 1.0438 - val_dense_3_RootMeanSquaredError: 0.6237 - val_dense_3_loss: 0.3889 - val_loss: 0.9787\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - dense_2_RootMeanSquaredError: 0.5797 - dense_2_loss: 0.3361 - dense_3_RootMeanSquaredError: 0.6268 - dense_3_loss: 0.3930 - loss: 0.3418 - val_dense_2_RootMeanSquaredError: 1.3401 - val_dense_2_loss: 1.7952 - val_dense_3_RootMeanSquaredError: 1.1409 - val_dense_3_loss: 1.3012 - val_loss: 1.7466\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5801 - dense_2_loss: 0.3366 - dense_3_RootMeanSquaredError: 0.6249 - dense_3_loss: 0.3906 - loss: 0.3420 - val_dense_2_RootMeanSquaredError: 1.3557 - val_dense_2_loss: 1.8371 - val_dense_3_RootMeanSquaredError: 0.7421 - val_dense_3_loss: 0.5506 - val_loss: 1.7092\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.5801 - dense_2_loss: 0.3365 - dense_3_RootMeanSquaredError: 0.6226 - dense_3_loss: 0.3878 - loss: 0.3417 - val_dense_2_RootMeanSquaredError: 1.6237 - val_dense_2_loss: 2.6353 - val_dense_3_RootMeanSquaredError: 1.2278 - val_dense_3_loss: 1.5068 - val_loss: 2.5236\n"
     ]
    }
   ],
   "source": [
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep),\n",
    "    (y_train, y_train),\n",
    "    epochs=20,\n",
    "    validation_data=(\n",
    "        (X_valid_wide, X_valid_deep),\n",
    "        (y_valid, y_valid)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5921 - dense_2_loss: 0.3508 - dense_3_RootMeanSquaredError: 0.6320 - dense_3_loss: 0.3994 - loss: 0.3556\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The predict() method returns a tuple, and it does not have a return_dict argument to get a dictionary instead. However, you can create one using model.output_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
    "y_pred = dict(zip(model.output_names, y_pred_tuple))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
