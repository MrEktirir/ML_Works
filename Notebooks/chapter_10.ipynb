{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perceptron\n",
    "\n",
    "* The perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron called a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scikit-Learn provides a Perceptron class that can be used pretty much as you would expect—for example, on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0) # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new) # predicts True and False for these 2 flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data,\n",
    "    housing.target,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    mlp_reg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053326657967967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "A = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(A.data, A.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.90357396\n",
      "Validation score: 0.333333\n",
      "Iteration 2, loss = 0.90026353\n",
      "Validation score: 0.333333\n",
      "Iteration 3, loss = 0.89697773\n",
      "Validation score: 0.333333\n",
      "Iteration 4, loss = 0.89371710\n",
      "Validation score: 0.333333\n",
      "Iteration 5, loss = 0.89049354\n",
      "Validation score: 0.333333\n",
      "Iteration 6, loss = 0.88729736\n",
      "Validation score: 0.333333\n",
      "Iteration 7, loss = 0.88412733\n",
      "Validation score: 0.333333\n",
      "Iteration 8, loss = 0.88098044\n",
      "Validation score: 0.333333\n",
      "Iteration 9, loss = 0.87786561\n",
      "Validation score: 0.333333\n",
      "Iteration 10, loss = 0.87478224\n",
      "Validation score: 0.333333\n",
      "Iteration 11, loss = 0.87170958\n",
      "Validation score: 0.333333\n",
      "Iteration 12, loss = 0.86867681\n",
      "Validation score: 0.333333\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=[5,8],\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    verbose = True,\n",
    "    alpha=0.01,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    mlp_clf\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 7,  4,  0],\n",
       "       [ 2, 10,  0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's look data shapes & types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For simplicity, we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0 (this also converts them to floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train/255.0, X_valid/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With MNIST, when the label is equal to 5, it means that the image represents the handwritten digit 5. Easy. For Fashion MNIST, however, we need the list of class names to know what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For example, the first image in the training set represents an ankle boot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let’s build the neural network! Here is a classification MLP with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\")) #Hidden 1\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\")) #Hidden 2\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of adding the layers one by one as we just did, it’s often more convenient to pass a list of layers when creating the Sequential model. You can also drop the Input layer and instead specify the input_shape in the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model = tf.keras.Sequential(\n",
    "#    [\n",
    "#        tf.keras.layers.Input(shape=[28, 28]),\n",
    "#        tf.keras.layers.Dense(300, activation=\"relu\"), #Hidden 1\n",
    "#        tf.keras.layers.Dense(100, activation=\"relu\"), #Hidden 2\n",
    "#        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model’s summary() method displays all the model’s layers,⁠ including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (None means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. Here we only have trainable parameters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that Dense layers often have a lot of parameters. For example, the first hidden layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters! This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can easily get a model’s list of layers using the layers attribute, or use the get_layer() method to access a layer by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06232093, -0.04144753, -0.00236116, ..., -0.04831953,\n",
       "         0.02645532,  0.07326569],\n",
       "       [-0.06841248, -0.01136567,  0.01530197, ...,  0.01934133,\n",
       "         0.04474924,  0.03255861],\n",
       "       [-0.02426652, -0.04916633, -0.01255452, ...,  0.04554836,\n",
       "         0.00215453, -0.01322366],\n",
       "       ...,\n",
       "       [ 0.06776233,  0.02078284,  0.06946106, ...,  0.05736829,\n",
       "         0.023509  , -0.04902883],\n",
       "       [-0.06855067, -0.02840155,  0.02313461, ..., -0.00069304,\n",
       "        -0.00617536,  0.02848803],\n",
       "       [ 0.04792387,  0.05444257, -0.03690857, ..., -0.02482099,\n",
       "        -0.03238373,  0.00320915]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer = \"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.6842 - loss: 0.9984 - val_accuracy: 0.8268 - val_loss: 0.5088\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8272 - loss: 0.5074 - val_accuracy: 0.8414 - val_loss: 0.4593\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8436 - loss: 0.4537 - val_accuracy: 0.8454 - val_loss: 0.4366\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8534 - loss: 0.4240 - val_accuracy: 0.8510 - val_loss: 0.4220\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.8598 - loss: 0.4025 - val_accuracy: 0.8512 - val_loss: 0.4109\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8652 - loss: 0.3852 - val_accuracy: 0.8564 - val_loss: 0.4014\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8700 - loss: 0.3708 - val_accuracy: 0.8594 - val_loss: 0.3931\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8732 - loss: 0.3579 - val_accuracy: 0.8598 - val_loss: 0.3862\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8768 - loss: 0.3467 - val_accuracy: 0.8610 - val_loss: 0.3813\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.3369 - val_accuracy: 0.8602 - val_loss: 0.3776\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8828 - loss: 0.3277 - val_accuracy: 0.8638 - val_loss: 0.3731\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.3193 - val_accuracy: 0.8650 - val_loss: 0.3667\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8890 - loss: 0.3115 - val_accuracy: 0.8650 - val_loss: 0.3664\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8916 - loss: 0.3043 - val_accuracy: 0.8686 - val_loss: 0.3616\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8938 - loss: 0.2976 - val_accuracy: 0.8698 - val_loss: 0.3604\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8966 - loss: 0.2913 - val_accuracy: 0.8700 - val_loss: 0.3598\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8988 - loss: 0.2851 - val_accuracy: 0.8708 - val_loss: 0.3579\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9013 - loss: 0.2795 - val_accuracy: 0.8716 - val_loss: 0.3574\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9034 - loss: 0.2739 - val_accuracy: 0.8728 - val_loss: 0.3575\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9055 - loss: 0.2685 - val_accuracy: 0.8716 - val_loss: 0.3610\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.2635 - val_accuracy: 0.8718 - val_loss: 0.3577\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2586 - val_accuracy: 0.8700 - val_loss: 0.3586\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9114 - loss: 0.2540 - val_accuracy: 0.8718 - val_loss: 0.3592\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9128 - loss: 0.2495 - val_accuracy: 0.8718 - val_loss: 0.3594\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9142 - loss: 0.2450 - val_accuracy: 0.8736 - val_loss: 0.3592\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2406 - val_accuracy: 0.8732 - val_loss: 0.3577\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2362 - val_accuracy: 0.8752 - val_loss: 0.3563\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9197 - loss: 0.2321 - val_accuracy: 0.8746 - val_loss: 0.3564\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9213 - loss: 0.2281 - val_accuracy: 0.8752 - val_loss: 0.3567\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2240 - val_accuracy: 0.8758 - val_loss: 0.3567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The fit() method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). If you use this dictionary to create a Pandas DataFrame and call its plot() method, you get the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Epoch'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 29],\n",
    "    ylim=[0, 1],\n",
    "    grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.3699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36752766370773315, 0.8737000226974487]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.01, 0.  , 0.71],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you only care about the class with the highest estimated probability (even if that probability is quite low), then you can use the argmax() method to get the highest probability class index for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let’s switch back to the California housing problem and tackle it using the same MLP as earlier, with 3 hidden layers composed of 50 neurons each, but this time building it with Keras. Using the sequential API to build, train, evaluate, and use a regression MLP is quite similar to what we did for classification. The main differences in the following code example are the fact that the output layer has a single neuron (since we only want to predict a single value) and it uses no activation function, the loss function is the mean squared error, the metric is the RMSE, and we’re using an Adam optimizer like Scikit-Learn’s MLPRegressor did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - RootMeanSquaredError: 1.1780 - loss: 1.4867 - val_RootMeanSquaredError: 0.6220 - val_loss: 0.3869\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.6337 - loss: 0.4020 - val_RootMeanSquaredError: 0.7184 - val_loss: 0.5162\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - RootMeanSquaredError: 0.6061 - loss: 0.3676 - val_RootMeanSquaredError: 0.5789 - val_loss: 0.3351\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5937 - loss: 0.3526 - val_RootMeanSquaredError: 1.0471 - val_loss: 1.0965\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5853 - loss: 0.3428 - val_RootMeanSquaredError: 1.0718 - val_loss: 1.1488\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5763 - loss: 0.3323 - val_RootMeanSquaredError: 0.6168 - val_loss: 0.3805\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5672 - loss: 0.3219 - val_RootMeanSquaredError: 0.7294 - val_loss: 0.5320\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5617 - loss: 0.3156 - val_RootMeanSquaredError: 0.6715 - val_loss: 0.4509\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5550 - loss: 0.3081 - val_RootMeanSquaredError: 0.7414 - val_loss: 0.5496\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5496 - loss: 0.3021 - val_RootMeanSquaredError: 0.6417 - val_loss: 0.4117\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5455 - loss: 0.2976 - val_RootMeanSquaredError: 0.9593 - val_loss: 0.9203\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5421 - loss: 0.2939 - val_RootMeanSquaredError: 0.6021 - val_loss: 0.3625\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - RootMeanSquaredError: 0.5394 - loss: 0.2911 - val_RootMeanSquaredError: 0.6776 - val_loss: 0.4592\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5350 - loss: 0.2863 - val_RootMeanSquaredError: 0.5342 - val_loss: 0.2854\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5315 - loss: 0.2826 - val_RootMeanSquaredError: 0.5803 - val_loss: 0.3368\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5288 - loss: 0.2797 - val_RootMeanSquaredError: 0.5308 - val_loss: 0.2817\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5273 - loss: 0.2781 - val_RootMeanSquaredError: 0.6054 - val_loss: 0.3665\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5250 - loss: 0.2757 - val_RootMeanSquaredError: 0.5398 - val_loss: 0.2914\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5240 - loss: 0.2747 - val_RootMeanSquaredError: 0.6406 - val_loss: 0.4104\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5222 - loss: 0.2728 - val_RootMeanSquaredError: 0.5539 - val_loss: 0.3068\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5334 - loss: 0.2846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API\n",
    "\n",
    "* It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.\n",
    "\n",
    "* Let’s build such a neural network to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_],\n",
    "    outputs=[output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path ? In this case, one solution is to use multiple inputs. For example, suppose we want to send five features through the wide path (features 0 to 4), and six features through the deep path (features 2 to 7). We can do this as follows.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5]) # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6]) # features 2 to 7\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can compile the model as usual, but when we call the fit() method, instead of passing a single input matrix X_train, we must pass a pair of matrices (X_train_wide, X_train_deep), one per input. The same is true for X_valid, and also for X_test and X_new when you call evaluate() or predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - RootMeanSquaredError: 1.9095 - loss: 3.7603 - val_RootMeanSquaredError: 0.9673 - val_loss: 0.9357\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.8773 - loss: 0.7711 - val_RootMeanSquaredError: 0.8126 - val_loss: 0.6603\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.7553 - loss: 0.5708 - val_RootMeanSquaredError: 0.7501 - val_loss: 0.5626\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.6982 - loss: 0.4877 - val_RootMeanSquaredError: 0.6514 - val_loss: 0.4244\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.6606 - loss: 0.4366 - val_RootMeanSquaredError: 0.6495 - val_loss: 0.4218\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.6352 - loss: 0.4036 - val_RootMeanSquaredError: 0.6076 - val_loss: 0.3691\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.6188 - loss: 0.3830 - val_RootMeanSquaredError: 0.9530 - val_loss: 0.9081\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.6093 - loss: 0.3714 - val_RootMeanSquaredError: 1.4306 - val_loss: 2.0466\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.6051 - loss: 0.3662 - val_RootMeanSquaredError: 1.6860 - val_loss: 2.8426\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.6034 - loss: 0.3642 - val_RootMeanSquaredError: 1.8851 - val_loss: 3.5535\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5982 - loss: 0.3579 - val_RootMeanSquaredError: 1.3902 - val_loss: 1.9327\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5954 - loss: 0.3546 - val_RootMeanSquaredError: 1.0780 - val_loss: 1.1621\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5871 - loss: 0.3447 - val_RootMeanSquaredError: 0.7243 - val_loss: 0.5246\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5834 - loss: 0.3404 - val_RootMeanSquaredError: 0.8028 - val_loss: 0.6445\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5808 - loss: 0.3374 - val_RootMeanSquaredError: 0.6356 - val_loss: 0.4039\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5799 - loss: 0.3364 - val_RootMeanSquaredError: 0.8062 - val_loss: 0.6500\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5765 - loss: 0.3324 - val_RootMeanSquaredError: 0.7308 - val_loss: 0.5341\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5753 - loss: 0.3310 - val_RootMeanSquaredError: 1.0461 - val_loss: 1.0944\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5747 - loss: 0.3303 - val_RootMeanSquaredError: 1.0436 - val_loss: 1.0891\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5743 - loss: 0.3299 - val_RootMeanSquaredError: 1.3078 - val_loss: 1.7103\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5881 - loss: 0.3460\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "history = model.fit((X_train_wide,X_train_deep), y_train, epochs=20, validation_data=((X_valid_wide,X_valid_deep),y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_wide, input_deep], \n",
    "    outputs=[output, aux_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each output will need its own loss function. Therefore, when we compile the model, we should pass a list of losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    loss=(\"mse\", \"mse\"),\n",
    "    loss_weights=(0.9, 0.1),\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now when we train the model, we need to provide labels for each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - dense_2_RootMeanSquaredError: 1.4526 - dense_2_loss: 2.1886 - dense_3_RootMeanSquaredError: 1.4956 - dense_3_loss: 2.2669 - loss: 2.1965 - val_dense_2_RootMeanSquaredError: 1.8381 - val_dense_2_loss: 3.3771 - val_dense_3_RootMeanSquaredError: 2.8507 - val_dense_3_loss: 8.1225 - val_loss: 3.8534\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.7539 - dense_2_loss: 0.5693 - dense_3_RootMeanSquaredError: 0.9233 - dense_3_loss: 0.8533 - loss: 0.5977 - val_dense_2_RootMeanSquaredError: 1.1011 - val_dense_2_loss: 1.2120 - val_dense_3_RootMeanSquaredError: 2.0310 - val_dense_3_loss: 4.1230 - val_loss: 1.5038\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.6616 - dense_2_loss: 0.4378 - dense_3_RootMeanSquaredError: 0.7832 - dense_3_loss: 0.6136 - loss: 0.4554 - val_dense_2_RootMeanSquaredError: 0.7248 - val_dense_2_loss: 0.5252 - val_dense_3_RootMeanSquaredError: 1.4994 - val_dense_3_loss: 2.2473 - val_loss: 0.6977\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.6378 - dense_2_loss: 0.4069 - dense_3_RootMeanSquaredError: 0.7408 - dense_3_loss: 0.5489 - loss: 0.4211 - val_dense_2_RootMeanSquaredError: 0.6396 - val_dense_2_loss: 0.4090 - val_dense_3_RootMeanSquaredError: 1.1980 - val_dense_3_loss: 1.4345 - val_loss: 0.5117\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.6275 - dense_2_loss: 0.3938 - dense_3_RootMeanSquaredError: 0.7199 - dense_3_loss: 0.5185 - loss: 0.4063 - val_dense_2_RootMeanSquaredError: 0.5942 - val_dense_2_loss: 0.3530 - val_dense_3_RootMeanSquaredError: 0.9653 - val_dense_3_loss: 0.9316 - val_loss: 0.4110\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.6220 - dense_2_loss: 0.3870 - dense_3_RootMeanSquaredError: 0.7080 - dense_3_loss: 0.5015 - loss: 0.3984 - val_dense_2_RootMeanSquaredError: 0.5889 - val_dense_2_loss: 0.3467 - val_dense_3_RootMeanSquaredError: 0.8695 - val_dense_3_loss: 0.7558 - val_loss: 0.3877\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.6119 - dense_2_loss: 0.3745 - dense_3_RootMeanSquaredError: 0.6907 - dense_3_loss: 0.4772 - loss: 0.3848 - val_dense_2_RootMeanSquaredError: 0.5822 - val_dense_2_loss: 0.3388 - val_dense_3_RootMeanSquaredError: 0.8077 - val_dense_3_loss: 0.6523 - val_loss: 0.3703\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.6062 - dense_2_loss: 0.3675 - dense_3_RootMeanSquaredError: 0.6790 - dense_3_loss: 0.4612 - loss: 0.3769 - val_dense_2_RootMeanSquaredError: 0.5795 - val_dense_2_loss: 0.3358 - val_dense_3_RootMeanSquaredError: 0.7608 - val_dense_3_loss: 0.5787 - val_loss: 0.3602\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.6021 - dense_2_loss: 0.3627 - dense_3_RootMeanSquaredError: 0.6697 - dense_3_loss: 0.4487 - loss: 0.3713 - val_dense_2_RootMeanSquaredError: 0.6483 - val_dense_2_loss: 0.4201 - val_dense_3_RootMeanSquaredError: 0.6629 - val_dense_3_loss: 0.4394 - val_loss: 0.4222\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.5977 - dense_2_loss: 0.3573 - dense_3_RootMeanSquaredError: 0.6601 - dense_3_loss: 0.4358 - loss: 0.3651 - val_dense_2_RootMeanSquaredError: 0.6032 - val_dense_2_loss: 0.3637 - val_dense_3_RootMeanSquaredError: 0.7280 - val_dense_3_loss: 0.5299 - val_loss: 0.3804\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.5936 - dense_2_loss: 0.3525 - dense_3_RootMeanSquaredError: 0.6523 - dense_3_loss: 0.4256 - loss: 0.3598 - val_dense_2_RootMeanSquaredError: 0.7470 - val_dense_2_loss: 0.5578 - val_dense_3_RootMeanSquaredError: 0.6365 - val_dense_3_loss: 0.4051 - val_loss: 0.5427\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.5905 - dense_2_loss: 0.3487 - dense_3_RootMeanSquaredError: 0.6455 - dense_3_loss: 0.4168 - loss: 0.3555 - val_dense_2_RootMeanSquaredError: 0.8063 - val_dense_2_loss: 0.6499 - val_dense_3_RootMeanSquaredError: 1.0936 - val_dense_3_loss: 1.1956 - val_loss: 0.7047\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.5890 - dense_2_loss: 0.3470 - dense_3_RootMeanSquaredError: 0.6426 - dense_3_loss: 0.4131 - loss: 0.3536 - val_dense_2_RootMeanSquaredError: 1.0349 - val_dense_2_loss: 1.0706 - val_dense_3_RootMeanSquaredError: 0.8879 - val_dense_3_loss: 0.7882 - val_loss: 1.0428\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.5868 - dense_2_loss: 0.3444 - dense_3_RootMeanSquaredError: 0.6364 - dense_3_loss: 0.4051 - loss: 0.3505 - val_dense_2_RootMeanSquaredError: 0.8725 - val_dense_2_loss: 0.7609 - val_dense_3_RootMeanSquaredError: 0.9760 - val_dense_3_loss: 0.9523 - val_loss: 0.7803\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.5839 - dense_2_loss: 0.3410 - dense_3_RootMeanSquaredError: 0.6320 - dense_3_loss: 0.3995 - loss: 0.3468 - val_dense_2_RootMeanSquaredError: 0.7238 - val_dense_2_loss: 0.5237 - val_dense_3_RootMeanSquaredError: 0.6421 - val_dense_3_loss: 0.4122 - val_loss: 0.5127\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.5814 - dense_2_loss: 0.3381 - dense_3_RootMeanSquaredError: 0.6281 - dense_3_loss: 0.3946 - loss: 0.3437 - val_dense_2_RootMeanSquaredError: 0.7353 - val_dense_2_loss: 0.5405 - val_dense_3_RootMeanSquaredError: 0.9840 - val_dense_3_loss: 0.9679 - val_loss: 0.5834\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.5788 - dense_2_loss: 0.3351 - dense_3_RootMeanSquaredError: 0.6255 - dense_3_loss: 0.3914 - loss: 0.3407 - val_dense_2_RootMeanSquaredError: 0.6954 - val_dense_2_loss: 0.4834 - val_dense_3_RootMeanSquaredError: 0.6610 - val_dense_3_loss: 0.4368 - val_loss: 0.4789\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_2_RootMeanSquaredError: 0.5773 - dense_2_loss: 0.3334 - dense_3_RootMeanSquaredError: 0.6219 - dense_3_loss: 0.3869 - loss: 0.3387 - val_dense_2_RootMeanSquaredError: 0.7721 - val_dense_2_loss: 0.5960 - val_dense_3_RootMeanSquaredError: 1.0068 - val_dense_3_loss: 1.0133 - val_loss: 0.6380\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.5760 - dense_2_loss: 0.3318 - dense_3_RootMeanSquaredError: 0.6196 - dense_3_loss: 0.3840 - loss: 0.3370 - val_dense_2_RootMeanSquaredError: 0.8253 - val_dense_2_loss: 0.6809 - val_dense_3_RootMeanSquaredError: 0.7842 - val_dense_3_loss: 0.6147 - val_loss: 0.6745\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - dense_2_RootMeanSquaredError: 0.5750 - dense_2_loss: 0.3306 - dense_3_RootMeanSquaredError: 0.6172 - dense_3_loss: 0.3811 - loss: 0.3357 - val_dense_2_RootMeanSquaredError: 0.9539 - val_dense_2_loss: 0.9095 - val_dense_3_RootMeanSquaredError: 1.6718 - val_dense_3_loss: 2.7937 - val_loss: 1.0984\n"
     ]
    }
   ],
   "source": [
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep),\n",
    "    (y_train, y_train),\n",
    "    epochs=20,\n",
    "    validation_data=(\n",
    "        (X_valid_wide, X_valid_deep),\n",
    "        (y_valid, y_valid)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - dense_2_RootMeanSquaredError: 0.5773 - dense_2_loss: 0.3334 - dense_3_RootMeanSquaredError: 0.6315 - dense_3_loss: 0.3989 - loss: 0.3400\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The predict() method returns a tuple, and it does not have a return_dict argument to get a dictionary instead. However, you can create one using model.output_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
    "y_pred = dict(zip(model.output_names, y_pred_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # needed to support naming the model\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\", name=\"my_cool_model\")\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_keras_model\", save_format=\"tf\")\n",
    "# model=tf.keras.load_model(\"my_keras_model\")\n",
    "# y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "    sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 50s]\n",
      "val_accuracy: 0.004392764996737242\n",
      "\n",
      "Best val_accuracy So Far: 0.004392764996737242\n",
      "Total elapsed time: 00h 05m 37s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    overwrite=True,\n",
    "    directory=\"my_fashion_mnist\",\n",
    "    project_name=\"my_rnd_search\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "random_search_tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can get the best models like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can also call get_best_hyperparameters() to get the kt.HyperParameters of the best models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 5,\n",
       " 'n_neurons': 25,\n",
       " 'learning_rate': 0.0006562536901904111,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "top3_params[0].values # best hyperparameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since the oracle keeps track of all the trials, you can ask it to give you the best one, and you can display a summary of that trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 5\n",
      "n_neurons: 25\n",
      "learning_rate: 0.0006562536901904111\n",
      "optimizer: sgd\n",
      "Score: 0.004392764996737242\n"
     ]
    }
   ],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This shows the best hyperparameters (like earlier), as well as the validation accuracy. You can also access all the metrics directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004392764996737242"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you are happy with the best model’s performance, you may continue training it for a few epochs on the full training set (X_train_full andy_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.0027 - loss: 2.2319\n",
      "Epoch 2/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.0027 - loss: 2.1588\n",
      "Epoch 3/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.0027 - loss: 2.0960\n",
      "Epoch 4/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.0027 - loss: 2.0390\n",
      "Epoch 5/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.0027 - loss: 1.9891\n",
      "Epoch 6/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.0027 - loss: 1.9436\n",
      "Epoch 7/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.0027 - loss: 1.9023\n",
      "Epoch 8/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.0027 - loss: 1.8652\n",
      "Epoch 9/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.0027 - loss: 1.8323\n",
      "Epoch 10/10\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.0027 - loss: 1.8033\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0016 - loss: 1.7979\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In some cases, you may want to fine-tune data preprocessing hyperparameters, or model.fit() arguments, such as the batch size. For this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = tf.keras.layers.Normalization()\n",
    "            X = norm_layer(X)\n",
    "        return model.fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can then pass an instance of this class to the tuner of your choice, instead of passing the build_model function. For example, let’s build a kt.Hyperband tuner based on a ``MyClassificationHyperModel`` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = kt.Hyperband(\n",
    "    MyClassificationHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=42,\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_fashion_mnist\",\n",
    "    project_name=\"hyperband\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let’s run the Hyperband tuner now. We’ll use the TensorBoard callback, this time pointing to the root log directory (the tuner will take care of using a different subdirectory for each trial), as well as an EarlyStopping callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 01m 41s]\n",
      "val_accuracy: 0.004392764996737242\n",
      "\n",
      "Best val_accuracy So Far: 0.004392764996737242\n",
      "Total elapsed time: 00h 37m 44s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_logdir = Path(hyperband_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "hyperband_tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[early_stopping_cb, tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* how much you want the algorithm to explore, instead of simply exploiting the known good regions of hyperparameter space (it defaults to 2.6). Other than that, this tuner can be used just like the previous ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 16s]\n",
      "val_accuracy: 0.004392764996737242\n",
      "\n",
      "Best val_accuracy So Far: 0.004392764996737242\n",
      "Total elapsed time: 00h 11m 55s\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner = kt.BayesianOptimization(\n",
    "    MyClassificationHyperModel(),\n",
    "    objective=\"val_accuracy\",\n",
    "    seed=42,\n",
    "    max_trials=10,\n",
    "    alpha=1e-4,\n",
    "    beta=2.6,\n",
    "    overwrite=True,\n",
    "    directory=\"my_fashion_mnist\",\n",
    "    project_name=\"bayesian_opt\"\n",
    ")\n",
    "\n",
    "bayesian_opt_tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "   validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "* Train a deep MLP on the MNIST dataset (you can load it using tf.keras. data⁠ sets.mnist.load_data()). See if you can get over 98% accuracy by manually tuning the hyperparameters. Try searching for the optimal learning rate by using the approach presented in this chapter (i.e., by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up). Next, try tuning the hyperparameters using Keras Tuner with all the bells and whistles—save checkpoints, use early stopping, and plot learning curves using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22d99155900>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "plt.imshow(X_train[0], cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's build a simple dense network and find the optimal learning rate. We will need a callback to grow the learning rate at each iteration. It will also record the learning rate and the loss at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tf.keras.backend\n",
    "\n",
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate.numpy() * self.factor\n",
    "        self.model.optimizer.learning_rate = lr\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will start with a small learning rate of 1e-3, and grow it by 0.5% at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's train the model for just 1 epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30ms/step - accuracy: 0.4865 - loss: nan - val_accuracy: 0.0958 - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1,\n",
    "    validation_data=(X_valid, y_valid), callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can now plot the loss as a functionof the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiUklEQVR4nO3deXhV1b3G8e8vM0lIAoQEAmFGZgFBZDZgVYoIFqt1wlkuRVt7r22trbXW9mp7bW+dBxTqcK2oVSogDhSJYZJJ5tEwQ5iRIQyBJOv+kYOmNIGA2Wcn2e/nec7D2Xuvc86PRThv1h7WNuccIiISXBF+FyAiIv5SEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMBF+V3A2YqMT3Yd27QkOvLsMuxEkWP/keMcPVFE/rFCipwjNiqCxLgokmKjSYiNwsyjoquhw4cPk5CQ4HcZNZ76OTwq2s+rth8kqVY0jVJqhaGq8Fq4cOEe51z9srZVuyDo0r41Cxcs+FbvsftQAR8szWP6mt18vn4vxwqLsehIerWsx4C2aXynXRoNk2veD8LZyM7OJisry+8yajz1c3hUtJ+7/W4q3+3UgN9f1cn7osLMzDaVt63aBUFl/NJev3Yst/Zpzq19mnP0eBGfb9hL9updTF+zm09X7+LX/4DOjZO5rEMDLu+QTsv6iZiGCyJSQ1W7IKhstWIiGdAmjQFt0njYOdbtPszHK3bwycqdPP7xGh7/eA3NUxO4rH06l3VIp2tmHSIiFAoiUnMEPghKMzNapSXSKq0Vdw9oxY4Dx5i6aiefrNjB2JkbeDFnPamJsQxsW5+BbdPo1TKV5FrRfpctIvKtKAhOo0FyHCN6NmVEz6YcPHaC7DW7+WTFDj5cvoO3F2wlJjKCS9qlcVXXRlx8Xn3ioiP9LllE5KwpCCooKS6aoZ0zGNo5gxNFxSzavJ8py7YzaUkeHy7fQVx0BH1apjKoYwMu79iApDiNFESkelAQnIPoyAh6NK9Lj+Z1+dUV7Zi9bi/TVu1k2qpdTFu9i19NWE5Wm/oM7ZLBJW3TqRWjkYKIVF0Kgm8pOjKCi8+rz8Xn1ee3Qx2Lt+xn4pI8Ji/dzicrdxIfE8l32qUzuFNDstpo95GIVD0KgkpkZnRtUoeuTerw4BXtmbt+L5OW5vHR8h1MXJJHQkwkQ7tkcGXnDC5sVvesL4oTEfGCgsAjkRFG71ap9G6VyiPDOvL5+r28vziPfyzK4815W0hNjGH4BY25tnsmrdIS/S5XRAJMQRAG0ZER9Gtdn36t6/Pw0A7M/HIP732xlXEzNzAmZz3dmtbh2u6NueL8DBJj9U8iIuGlb50wS4yNYlDHBgzq2IDdhwqYsGgrb83fwv3vLuO3k1ZyRaeGXHthJt2b1tHVzCISFgoCH9WvHcvI/i25q18LFm3Zz9vztzBpSR7vLNxKi9QEfnBhJtf1aKKL1kTEUwqCKsDMuKBJHS5oUoeHrmzPlGU7eHv+Fh77cDVPf5rLDRc14bY+zQI/EZ6IeENBUMXEx0Tx/W6N+X63xqzIO8CYnPWMnbmBcTM3MKxLI0b2b0GbBrX9LlOkRnJ+F+ATnb9YhXXISObJ67qS/dMsburZlCnLtnP5Eznc8cp8VuQd8Ls8kRrJKmWO4+pFQVANZNaN5+GhHZj9i4H816XnMX/jPq54aiaj31jImh2H/C5PRKo5BUE1Uichhh9f0poZ9w/kRwNbkbN2D5c/kcPdb3yhQBCRc6YgqIaSa0Vz32VtmHn/AH40sBWfrd3N5U/kcN/bS9hx4Jjf5YlINaMgqMZS4mO+DoT/6N+CSUvyuPjx6Tw6ZRUHjpzwuzwRqSYUBDVASnwMDwxux7T7LmbI+Rm8NGM9WX+azv99vomi4qCeByEiFaUgqEEy68bz52s788GP+nFeem0e/Mdyhj4zk0Wbv/K7NBGpwhQENVD7jCTGj+zJMzd0ZU9+AcOfn82D/1jG4YJCv0sTkSpIQVBDmRlDzs9g2n1Z3Na7OW/M3czgp2awcJNGByLyrxQENVxibBQPXdme8Xf1pKjYcc0Ls/njR6spKCzyuzQRqSIUBAFxUYt6fHhvP67plsnz2eu48umZLN263++yRKQKUBAESO24aP74/fP5660XcuDoCb733Gz+9PEajQ5EAk5BEEAD2qbxyX9ezPCujXhmei7DnpnFyryDfpclIj5REARUcq1oHr+mM+Nu7c6+w8e56tlZvDJrA87pugORoPEsCMws08ymm9lKM1thZveW0cbM7CkzyzWzpWZ2gVf1SNkGtk3no5/0p1/rVB6etJK7XlvAvsPH/S5LRMLIyxFBIXCfc6490BO428zan9Lmu0Dr0GMk8LyH9Ug56ibE8PIt3XloSHty1u5h8JMzyN2v4wYSPEEdEXsWBM657c65L0LPDwGrgEanNBsGvOZKfA6kmFlDr2qS8pkZt/dtznujexMdZTw29xh/m7vZ77JEwi6ItwoPyx3KzKwZ0BWYe8qmRsCWUstbQ+u2n/L6kZSMGEhPTyc7O9urUgW4v4vx7BeOX05Yxj8XruKmdjFEBPF/Rxjk5+fr5zkMKtrPJ06cYNu2bWRn7/G+qCrE8yAws0TgXeAnzrlzOjXFOTcGGAPQvXt3l5WVVXkFSpnio6cz92gDXsxZT0RCXZ66vivxMbqzaWXLzs5GP8/eq2g/R+d8QqNGGWRldfS+qCrE07OGzCyakhB4wzn3XhlNtgGZpZYbh9aJzyLMeGBwOx4Z1oFpq3dx/ZjP2ZNf4HdZIuIBL88aMmAssMo597/lNJsI3Bw6e6gncMA5t72ctuKDm3s148WburFm5yGGPzeb9bvz/S5JRCqZlyOCPsAIYKCZLQ49BpvZKDMbFWozBVgP5AIvAaM9rEfO0WUdGvDmXT3JLyjk6udns3DTPr9LEpFK5NlOX+fcTOC0Rxhdyblad3tVg1Serk3q8N4Pe3PrX+dxw0tzeeIHXfhuJ53gJVIT6MpiqbBmqQm8+8PetM9IYvTfvuDV2Rv9LklEKoGCQM5KvcRY/nZnTy5pm85vJq7gsSmrKCwq9rssEfkWFARy1mrFRPLCTRdw40VNeDFnPTePm6czikSqMQWBnJOoyAj++3ud+J+rz2fhpq8Y8tRMlm094HdZInIOFATyrVx7YSbv/rA3kRHGtS/O4Z8rd/pdkoicJQWBfGsdGyUz4e7etE5PZOTrC3htzka/SxKRs6AgkEqRVjuO8SN7MrBtOg+9v4LfTV5JUXEwZ3IUqW4UBFJp4mOieHFEN27r04yxMzcw+o2FHD2u6axFqjoFgVSqyAjjN1d24KEh7flk5U6ue+lzdh/SGUVSPQR1DKsgEE/c3rd5yRxFOw7yvedmkbvrkN8liVRIECdcVxCIZy7r0IC3Rvbi2Ilihj83m9nrgjXHu0h1oSAQT3XOTGHC6N6kJ8Vx89h5vDF3k98licgpFATiucy68bw7ujf9WqfyqwnLeej95ZqWQqQKURBIWCTFRfPyLRcysn8LXpuziZGvL+RwQaHfZYkICgIJo8gI45eD2/Hf3+vIZ2t3c+2Lc9h58JjfZYkEnoJAwu7Gi5ry8i3d2bjnMFc9O4tV28/pVtYiUkkUBOKLAW3SeGdUb5yDa16Yw2drd/tdkkhgKQjEN+0zkphwd28y68Zz+yvzGTdzAyU3rRORcFIQiK8aJtfinVG9uKRtGo9MXsnDE1fojCKRMFMQiO8SY6N44aZu3Nm3Oa/O2cSdry3g4LETfpclEhgKAqkSIiKMB4e059HvdWLml3sY/txsNu097HdZIoGgIJAq5YaLmvDaHT3Yk1/AsGdnkaODyCKeUxBIldO7ZSrv392HBklx3PLXeTyXnauDyCIeUhBIldS0XgLvje7NFZ0a8j8freGeNxdx5LiuRBbxgoJAqqz4mCievr4r9w9qy5Rl2xn+3Gw27z3id1lSgxUVOSIigjcRtYJAqjQz44dZLXnlth7k7T/K0GdnMvNLTWct3jhWWERcdKTfZYSdgkCqhYvPq8/Ee/qSVjuWm8fNZUzOOh03kEpVVOw4UeSIi1IQiFRZzVITmDC6D4M6NuDRKau5d/xi3RNZKs2xEyU/S3HRwftaDN7fWKq1hNgonr3hAn52eRsmLc3jymdmsnjLfr/LkhrgZBDERgXvazF4f2Op9syMuwe04rXbe3CkoJBrXpjNWM1TJN/S3sPHAagVo11DItVGv9b1+fDe/mS1SeN3k1cy6v8WcuCopqaQc7N+dz4ArdISfa4k/BQEUq0lx0czZkQ3HryiHdNW7WLI0zNYtvWA32VJNXRyQJkQG+VvIT5QEEi1Z2bc2a8Fb/1HL4qKHFc/P5vX5mzUriI5K8WhHxdD1xGIVFvdmtbhgx/3o0+rejz0/gpGvr6QfaH9viJn4ihJAgteDigIpGapkxDD2Fsu5MEr2pG9ZhfffTKHWbm6AE3OzH09IggeBYHUOBERJbuKJozuQ2JsFDeNncsfPlzN8ULd8EbKd3JHokYEIjVIx0bJTPpRX667sAkvfLaOq5+f/fWZISKn+uaYUvCSwLMgMLNxZrbLzJaXsz3LzA6Y2eLQ4yGvapHgio+J4rHhnXjhpm5s+eoIQ56eyZvzNutAspRLI4LK9Qow6AxtZjjnuoQej3hYiwTcoI4N+PDefnRunMID7y1jxNh5bNt/1O+ypArRMQIPOOdygH1evb/I2WqYXIs37ryI313VkS82f8Xlf8nhrfkaHUiJb84aCl4UmJf/CcysGTDZOdexjG1ZwLvAViAP+KlzbkU57zMSGAmQnp7ebfz48R5VLCfl5+eTmFhzr7DcdaSYscsKWPNVMeenRnJLhxjq1Qr/IbOa3s9VRUX6eda2E7y07Dh/7FeL9ISad/h0wIABC51z3cva5mcQJAHFzrl8MxsMPOmca32m9+zevbtbsGBB5Rcr/yI7O5usrCy/y/BUcbHjtTkb+cNHqzGMewa24o6+zcM6H30Q+rkqqEg/v7twK/e9s4TPfpZF03oJ4SksjMys3CDwLfaccwedc/mh51OAaDNL9aseCZ6ICOPWPs2Z+p8X0/+8VB7/eA2XP5HDtFU7/S5NfHDyV+KIAO4a8i0IzKyBhXbGmVmPUC17/apHgiuzbjwvjujO63f0IDoygjteXcDtr8xn457DfpcmYVQc4GNFXp4++iYwB2hjZlvN7A4zG2Vmo0JNvg8sN7MlwFPAdU5H7cRHJbOZ9uNXg9sxd/1eLvtLDn/6eI1ufhMUJ88aCt6AAM+m2XPOXX+G7c8Az3j1+SLnIjoygrv6t2BYlwwenbKKZ6bnMmHRNn49pD2Xd0gP5BklQRHks4Zq3qFxkUqQlhTHE9d15a2RPUmMjWLU/y3kxpfnsnrHQb9LE4/oOgIRKdNFLerxwY/78siwDqzcfpDBT87gwX8s06ymNZDmGhKRckVFRnBzr2Zk/zSLm3s14815W8h6fDrjZm7gRJEmsqspnO5HICJnkhIfw8NDO/DRvf3onJnCI5NXMvjJGcz4crffpUkl0P0IRKTCWqfX5rXbezBmRDcKCosZMXYeI8bOZfk23SKzOtMxAhE5K2bGZR0aMPW/+vPrIe1Zvu0AQ56eyb3jF7Fpr64/qI6+Pnc9gEkQvLs0i1Si2KhI7ujbnGu6N+aF7HWMm7WBD5Zu5wcXZvLDrJY0rhPvd4lSUaEhgY4RiMg5SYqL5ueD2pLzswFc36MJby/YQtbj2fz870t0hXI18c0UE76W4QsFgUglSkuK43dXdSTn5wO4qWdT3l+cx8A/Z/OT8YvI3XXI7/LkNIqLdUGZiFSihsm1eHhoB2bcP4A7+7Xgk5U7ufQvOYx+YyEr83RRWlUU3BtV6hiBiKfSasfxy8HtGHVxS8bN3MCrszcyZdkOLmmbxh39muumOFWI01xDIuKlugkx/PTyNtzVvwWvzNrIq3M2csNLc2lSO4J9SVu5snMGMVEaoPvpmxFB8JJAP3kiYZRcK5p7v9Oa2b8YyB+Gd6LQOe57Zwn9/2c6L89Yz6FjJ/wuMbBcgC8k0IhAxAdx0ZFc16MJ6YfXYRkdeD57Hb//YBVP/vNLbrioCbf2aUbD5Fp+lxlI2jUkImFlZmS1SSOrTRqLt+znpRnreWnGesbO3MDQzhnc2a8F7TOS/C4zEAI8IKhYEJhZAnDUOVdsZucBbYEPnXMax4pUki6ZKTx7wwVs2XeEcbM28Nb8Lby3aBv9WqdyV78W9GudGshTG8NF9yM4sxwgzswaAZ8AI4BXvCpKJMgy68bzmys7MOcXl/DzQW1Ys+MQN4+bx2V/yeHNeZs5dkJ3TPNCkEcEFQ0Cc84dAYYDzznnrgE6eFeWiCTHRzM6qxUz7h/An6/pTHRkBA+8t4xej03jTx+vYXbuHgoKFQqVJcj3I6joMQIzs17AjcAdoXWR3pQkIqXFRkVydbfGDL+gEXM37GPszA08m53LM9NzSa4VzdDOGVzXI5MOGcl+l1qtnRwRRAQwCSoaBD8BHgAmOOdWmFkLYLpnVYnIvzEzeraoR88W9di2/ygr8w4yaUkeby/Ywuufb6JLZgrX98hkcKeG1I6L9rvcaqc4wBf3VSgInHOfAZ8BmFkEsMc592MvCxOR8jVKqUWjlFpc2j6d/UeO894X2/jbvM3c/+4yHnp/BZd3aMDV3RrTt1UqkUGcRe1bCOCAoMJnDf0NGAUUAfOBJDN70jn3uJfFiciZpcTHcHvf5tzWpxmLt+zn3S+2MmnJdiYuySMjOY6ruzVmWJdGtEpL9LvUKs0FeBrqiu4aau+cO2hmNwIfAr8AFgIKApEqwszo2qQOXZvU4ddD2vPPlbsYP38zz07P5elPc+ncOJnBnRpySbs0WqXV9rvcKkdzDZ1ZtJlFA1cBzzjnTphZcHeoiVRxsVGRXHF+Q644vyG7Dh5j4pI8JizaxmMfruaxD1dzXnoiV56fwZWdM2iWmuB3uVWCZh89sxeBjcASIMfMmgKaS1ekGkhLiuPOfi24s18L8vYfZerKnUxemsefp67lz1PX0qlRMld2bsgV52fQKCW401p8MyIIXhRU9GDxU8BTpVZtMrMB3pQkIl7JSKnFLb2bcUvvZuTtP8oHS7czeWkej05ZzaNTVtO9aR2GnN+Qyzs2CNxcR19fWexzHX6o6MHiZOA3QP/Qqs+AR4ADHtUlIh7LSKnFXf1bcFf/Fmzae5jJS7czaUkeD09aycOTVtI8NYGBbdO4tH063ZvWISqyZk9WrGMEZzYOWA5cG1oeAfyVkiuNRaSaa1ovgbsHtOLuAa34cuchPlu7mxlf7uH1OZsYO3MDKfHRDGxTEgr9z6tPQmzNm6/ymyuLg5cEFf3XbOmcu7rU8m/NbLEH9YiIz1qn16Z1em3u7NeC/IJCctbuZurKnUxbvYv3Fm0jJjKC3q3qcWn7dL7TLp30pDi/S64cuqDsjI6aWV/n3EwAM+sDHPWuLBGpChJjoxjcqSGDOzWksKiY+Ru/YurKnUxdtYPsCbv51YTldG6czKXt0+nXuj4dGyVX2wvYHMHcLQQVD4JRwGuhYwUAXwG3eFOSiFRFUZER9GpZj14t6/HrIe1YuzOfqSt3MHXVLv70yVr+9MlaUuKj6ZKZQt9WqXynXTpN68VXm10th44VkhhT83Z5VURFzxpaAnQ2s6TQ8kEz+wmw1MPaRKSKMjPaNKhNmwa1uWdga3YdOsacdXuZlbuHhZu+4vcfrOL3H6yiXkIMXTJT6NWyHr1bptK2QW0iquiIYfuBozRIriG7uc7SWcWfc670tQP/BTxRqdWISLWUVjuOYV0aMaxLIwA27z3CZ2t3sWTrAb7Y9BXTVu8CoG5CDBc0qUN6UiwXNKlDSnw0L+asp7ComLTacTSpF0+r+okkxkXRvmFSWEcUOw4WKAjOQdWMdRHxXZN68Yzo1YwRoeXtB44yO3cvs9bt4YtNX/H5+r28MXczAKmJsZyXnsi63fl8umYXxwuLv36flPhoOjdOoXNmCl0yk2laL4EGSXEkxEZxuKCQj1fsIMKMhNgoGibH0SotEbOS+YJm5e5h9Y5DxEZFsHnLCQ4s3kZ8TBT1a8fSrF48ybVKZmg9GTR5+4/S+rz6Ye2nqsLcOR4pN7PNzrkmlVzPGdVt2s5d+stx4f7YwNm/fz8pKSl+l1HjBbmfjxwv4tiJIpJqRRMV2l3kgOOFxRQWF3O4oIj8gkLyjxVy9JS7ssVFR1Bc7DhedO5n+piVnCgUExlBZAQcPVFMk7rxNKyho4K3R/Ve6JzrXta2044IzOwQ35xe+y+bgGBddigilSo+JpL4mH+9v5UBsVERxBJBQkwUabVjgZJ7BRwuKKKgsIiCE8XkHy/k2PEimtStRZ34aIqKHQWFxRw9XlTyJg7iYiJJiY/GOdi//wCJtWtTVOw4XlTMsRPFHC8swsw4UVRMQWExqbFRpCfFhr8jqoBzHhH4pXv37m7BggV+l1HjZWdnk5WV5XcZNZ76OTzUz2Bm5Y4IPLtm3MzGmdkuM1teznYzs6fMLNfMlprZBV7VIiIi5fNy8pBXgEGn2f5doHXoMRJ43sNaRESkHJ4FgXMuB9h3mibDgNdcic+BFDNr6FU9IiJSNj8vo2sEbCm1vDW0bvupDc1sJCWjBtLT08nOzg5HfYGWn5+vfg4D9XN4qJ9Pr1pcT+2cGwOMgZKDxUE/6BMOOrgWHurn8FA/n56fE4xvAzJLLTcOrRMRkTDyMwgmAjeHzh7qCRxwzv3bbiEREfGWZ7uGzOxNIAtINbOtlNzhLBrAOfcCMAUYDOQCR4DbvKpFRETK51kQOOeuP8N2B9zt1eeLiEjF1OybkIqIyBkpCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnKdBYGaDzGyNmeWa2S/K2H6rme02s8Whx51e1iMiIv8uyqs3NrNI4FngUmArMN/MJjrnVp7S9C3n3D1e1SEiIqfn5YigB5DrnFvvnDsOjAeGefh5IiJyDjwbEQCNgC2llrcCF5XR7moz6w+sBf7TObfl1AZmNhIYCZCenk52dnblVyv/Ij8/X/0cBurn8FA/n56XQVARk4A3nXMFZvYfwKvAwFMbOefGAGMAunfv7rKyssJaZBBlZ2ejfvae+jk81M+n5+WuoW1AZqnlxqF1X3PO7XXOFYQWXwa6eViPiIiUwcsgmA+0NrPmZhYDXAdMLN3AzBqWWhwKrPKwHhERKYNnu4acc4Vmdg/wMRAJjHPOrTCzR4AFzrmJwI/NbChQCOwDbvWqHhERKZunxwicc1OAKaese6jU8weAB7ysQURETk9XFouIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAKQhERAJOQSAiEnAKAhGRgFMQiIgEnIJARCTgFAQiIgGnIBARCTgFgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYGISMApCEREAk5BICIScAoCEZGAUxCIiAScgkBEJOAUBCIiAacgEBEJOAWBiEjAeRoEZjbIzNaYWa6Z/aKM7bFm9lZo+1wza+ZlPSIi8u88CwIziwSeBb4LtAeuN7P2pzS7A/jKOdcK+AvwR6/qERGRsnk5IugB5Drn1jvnjgPjgWGntBkGvBp6/nfgEjMzD2sSEZFTRHn43o2ALaWWtwIXldfGOVdoZgeAesCe0o3MbCQwMrSYb2ZrPKn43yUDB8L0+oq0PV2b8raVtb4i61I55d/BQ+rn8FA/h0dV7eem5bZwznnyAL4PvFxqeQTwzCltlgONSy2vA1K9qukc/g5jwvX6irQ9XZvytpW1viLrgAXqZ/Wz+rlm9/PJh5e7hrYBmaWWG4fWldnGzKIoSa69HtZ0tiaF8fUVaXu6NuVtK2t9RdeFi/o5PNTP4VGd+hkACyVGpQt9sa8FLqHkC38+cINzbkWpNncDnZxzo8zsOmC4c+5aTwqSs2JmC5xz3f2uo6ZTP4eH+vn0PDtG4Er2+d8DfAxEAuOccyvM7BFKhmkTgbHA62aWC+wDrvOqHjlrY/wuICDUz+Ghfj4Nz0YEIiJSPejKYhGRgFMQiIgEnIJARCTgFARy1szsKjN7KTRP1GV+11NTmVkLMxtrZn/3u5aaxMwSzOzV0M/wjX7XUxUoCALGzMaZ2S4zW37K+tNOEFiac+4fzrm7gFHAD7yst7qqpH5e75y7w9tKa4az7O/hwN9DP8NDw15sFaQgCJ5XgEGlV5Q3QaCZdTKzyac80kq99MHQ6+TfvULl9bOc2StUsL8pubj15PQ3RWGsscrycq4hqYKcczllTPf99QSBAGY2HhjmnHsMGHLqe4QmBvwD8KFz7guPS66WKqOfpeLOpr8pmfesMbAY/TIMqBOkRFkTBDY6TfsfAd8Bvm9mo7wsrIY5q342s3pm9gLQ1cwe8Lq4Gqi8/n4PuNrMnsffqSiqDI0I5Kw5554CnvK7jprOObeXkuMwUomcc4eB2/yuoyrRiECgYhMEyrenfg4v9XcFKQgESiYEbG1mzc0shpI5nyb6XFNNpH4OL/V3BSkIAsbM3gTmAG3MbKuZ3eGcKwROThC4Cni79CyxcvbUz+Gl/v52NOmciEjAaUQgIhJwCgIRkYBTEIiIBJyCQEQk4BQEIiIBpyAQEQk4BYHUGGaWH+bPmx3mz0sxs9Hh/EwJBgWBSDnM7LRzcTnneof5M1MABYFUOgWB1Ghm1tLMPjKzhWY2w8zahtZfaWZzzWyRmf3TzNJD6x82s9fNbBbwemh5nJllm9l6M/txqffOD/2ZFdr+dzNbbWZvhKbqxswGh9YtNLOnzGxyGTXeamYTzexTYJqZJZrZNDP7wsyWmdmwUNM/AC3NbLGZPR567c/MbL6ZLTWz33rZl1KDOef00KNGPID8MtZNA1qHnl8EfBp6Xodvrqy/E/hz6PnDwEKgVqnl2UAskArsBaJLfx6QBRygZFKzCEqmOugLxFEyDXLzULs3gcll1HgrJVMk1w0tRwFJoeepQC5gQDNgeanXXQaMCW2LACYD/f3+d9Cj+j00DbXUWGaWCPQG3gn9gg4lX+hQ8qX9lpk1BGKADaVeOtE5d7TU8gfOuQKgwMx2AemUfHGXNs85tzX0uYsp+dLOB9Y7506+95vAyHLKneqc23eydOBRM+sPFFMyh356Ga+5LPRYFFpOBFoDOeV8hkiZFARSk0UA+51zXcrY9jTwv865iWaWRclv/icdPqVtQannRZT9/6YibU6n9GfeCNQHujnnTpjZRkpGF6cy4DHn3Itn+Vki/0LHCKTGcs4dBDaY2TVQcotNM+sc2pzMN3PT3+JRCWuAFqVuofiDCr4uGdgVCoEBQNPQ+kNA7VLtPgZuD418MLNGutexnAuNCKQmiTez0rts/peS366fN7MHgWhgPLCEkhHAO2b2FfAp0Lyyi3HOHQ2d7vmRmR2mZH78ingDmGRmy4AFwOrQ++01s1lmtpyS+0X/zMzaAXNCu77ygZuAXZX9d5GaTdNQi3jIzBKdc/mhs4ieBb50zv3F77pEStOuIRFv3RU6eLyCkl0+2p8vVY5GBCIiAacRgYhIwCkIREQCTkEgIhJwCgIRkYBTEIiIBJyCQEQk4P4faZeuGPhMbdcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The loss starts shooting back up violently when the learning rate goes over 6e-1, so let's try using half of that, at 3e-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=3e-1)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('my_mnist_logs/run_001')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1\n",
    "run_logdir = Path() / \"my_mnist_logs\" / \"run_{:03d}\".format(run_index)\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17ms/step - accuracy: 0.8697 - loss: 0.4147 - val_accuracy: 0.9708 - val_loss: 0.1078\n",
      "Epoch 2/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.9693 - loss: 0.1022 - val_accuracy: 0.9744 - val_loss: 0.0880\n",
      "Epoch 3/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - accuracy: 0.9810 - loss: 0.0610 - val_accuracy: 0.9768 - val_loss: 0.0850\n",
      "Epoch 4/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.9859 - loss: 0.0426 - val_accuracy: 0.9760 - val_loss: 0.0853\n",
      "Epoch 5/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - accuracy: 0.9905 - loss: 0.0309 - val_accuracy: 0.9730 - val_loss: 0.1019\n",
      "Epoch 6/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.9916 - loss: 0.0260 - val_accuracy: 0.9792 - val_loss: 0.0844\n",
      "Epoch 7/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 29ms/step - accuracy: 0.9933 - loss: 0.0207 - val_accuracy: 0.9788 - val_loss: 0.0944\n",
      "Epoch 8/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.9922 - loss: 0.0229 - val_accuracy: 0.9772 - val_loss: 0.0996\n",
      "Epoch 9/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9938 - loss: 0.0186 - val_accuracy: 0.9826 - val_loss: 0.0929\n",
      "Epoch 10/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.9776 - val_loss: 0.1134\n",
      "Epoch 11/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - accuracy: 0.9949 - loss: 0.0150 - val_accuracy: 0.9798 - val_loss: 0.1055\n",
      "Epoch 12/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9760 - val_loss: 0.1377\n",
      "Epoch 13/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - accuracy: 0.9962 - loss: 0.0114 - val_accuracy: 0.9816 - val_loss: 0.1088\n",
      "Epoch 14/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - accuracy: 0.9961 - loss: 0.0121 - val_accuracy: 0.9782 - val_loss: 0.1225\n",
      "Epoch 15/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9812 - val_loss: 0.1051\n",
      "Epoch 16/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9957 - loss: 0.0137 - val_accuracy: 0.9818 - val_loss: 0.1008\n",
      "Epoch 17/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.9804 - val_loss: 0.1070\n",
      "Epoch 18/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9814 - val_loss: 0.1099\n",
      "Epoch 19/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9842 - val_loss: 0.1054\n",
      "Epoch 20/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9800 - val_loss: 0.1298\n",
      "Epoch 21/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 0.9854 - val_loss: 0.0999\n",
      "Epoch 22/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.9996 - loss: 9.1720e-04 - val_accuracy: 0.9844 - val_loss: 0.1073\n",
      "Epoch 23/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.6508e-04 - val_accuracy: 0.9856 - val_loss: 0.1056\n",
      "Epoch 24/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 6.7053e-05 - val_accuracy: 0.9854 - val_loss: 0.1055\n",
      "Epoch 25/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 5.0527e-05 - val_accuracy: 0.9858 - val_loss: 0.1057\n",
      "Epoch 26/100\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.2725e-05 - val_accuracy: 0.9860 - val_loss: 0.1060\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_mnist_model.keras\", save_best_only=True)\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08024095743894577, 0.9787999987602234]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"my_mnist_model.keras\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We got over 98% accuracy. Finally...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
