{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perceptron\n",
    "\n",
    "* The perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt. It is based on a slightly different artificial neuron called a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scikit-Learn provides a Perceptron class that can be used pretty much as you would expect—for example, on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0) # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new) # predicts True and False for these 2 flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data,\n",
    "    housing.target,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(\n",
    "    hidden_layer_sizes=[50, 50, 50],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    mlp_reg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053326657967967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "A = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(A.data, A.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.90357396\n",
      "Validation score: 0.333333\n",
      "Iteration 2, loss = 0.90026353\n",
      "Validation score: 0.333333\n",
      "Iteration 3, loss = 0.89697773\n",
      "Validation score: 0.333333\n",
      "Iteration 4, loss = 0.89371710\n",
      "Validation score: 0.333333\n",
      "Iteration 5, loss = 0.89049354\n",
      "Validation score: 0.333333\n",
      "Iteration 6, loss = 0.88729736\n",
      "Validation score: 0.333333\n",
      "Iteration 7, loss = 0.88412733\n",
      "Validation score: 0.333333\n",
      "Iteration 8, loss = 0.88098044\n",
      "Validation score: 0.333333\n",
      "Iteration 9, loss = 0.87786561\n",
      "Validation score: 0.333333\n",
      "Iteration 10, loss = 0.87478224\n",
      "Validation score: 0.333333\n",
      "Iteration 11, loss = 0.87170958\n",
      "Validation score: 0.333333\n",
      "Iteration 12, loss = 0.86867681\n",
      "Validation score: 0.333333\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=[5,8],\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    verbose = True,\n",
    "    alpha=0.01,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    mlp_clf\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 7,  4,  0],\n",
       "       [ 2, 10,  0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's look data shapes & types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For simplicity, we’ll scale the pixel intensities down to the 0–1 range by dividing them by 255.0 (this also converts them to floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train/255.0, X_valid/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With MNIST, when the label is equal to 5, it means that the image represents the handwritten digit 5. Easy. For Fashion MNIST, however, we need the list of class names to know what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For example, the first image in the training set represents an ankle boot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let’s build the neural network! Here is a classification MLP with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\")) #Hidden 1\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\")) #Hidden 2\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of adding the layers one by one as we just did, it’s often more convenient to pass a list of layers when creating the Sequential model. You can also drop the Input layer and instead specify the input_shape in the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model = tf.keras.Sequential(\n",
    "#    [\n",
    "#        tf.keras.layers.Input(shape=[28, 28]),\n",
    "#        tf.keras.layers.Dense(300, activation=\"relu\"), #Hidden 1\n",
    "#        tf.keras.layers.Dense(100, activation=\"relu\"), #Hidden 2\n",
    "#        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model’s summary() method displays all the model’s layers,⁠ including each layer’s name (which is automatically generated unless you set it when creating the layer), its output shape (None means the batch size can be anything), and its number of parameters. The summary ends with the total number of parameters, including trainable and non-trainable parameters. Here we only have trainable parameters.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that Dense layers often have a lot of parameters. For example, the first hidden layer has 784 × 300 connection weights, plus 300 bias terms, which adds up to 235,500 parameters! This gives the model quite a lot of flexibility to fit the training data, but it also means that the model runs the risk of overfitting, especially when you do not have a lot of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can easily get a model’s list of layers using the layers attribute, or use the get_layer() method to access a layer by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00049778,  0.00925973,  0.03838651, ..., -0.00758467,\n",
       "        -0.02532194, -0.04929992],\n",
       "       [ 0.0593904 , -0.03897049,  0.05628741, ..., -0.06999838,\n",
       "        -0.03188821,  0.07334428],\n",
       "       [-0.01684529, -0.05768779,  0.00955462, ...,  0.03801399,\n",
       "         0.02149417,  0.02796468],\n",
       "       ...,\n",
       "       [-0.05845927, -0.06962658, -0.00659122, ...,  0.01727479,\n",
       "         0.06437582,  0.03185485],\n",
       "       [-0.06978955, -0.02280233, -0.05710053, ..., -0.01990283,\n",
       "        -0.07003708,  0.01892317],\n",
       "       [ 0.04957885,  0.0584175 ,  0.0384835 , ..., -0.03714766,\n",
       "        -0.05713292,  0.04120141]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer = \"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.6731 - loss: 1.0173 - val_accuracy: 0.8272 - val_loss: 0.5063\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8275 - loss: 0.5063 - val_accuracy: 0.8344 - val_loss: 0.4568\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8441 - loss: 0.4523 - val_accuracy: 0.8458 - val_loss: 0.4336\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8536 - loss: 0.4223 - val_accuracy: 0.8516 - val_loss: 0.4180\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8601 - loss: 0.4006 - val_accuracy: 0.8534 - val_loss: 0.4065\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8653 - loss: 0.3837 - val_accuracy: 0.8548 - val_loss: 0.3979\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8697 - loss: 0.3696 - val_accuracy: 0.8592 - val_loss: 0.3879\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8743 - loss: 0.3575 - val_accuracy: 0.8614 - val_loss: 0.3810\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8779 - loss: 0.3468 - val_accuracy: 0.8638 - val_loss: 0.3769\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8811 - loss: 0.3374 - val_accuracy: 0.8668 - val_loss: 0.3712\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8839 - loss: 0.3284 - val_accuracy: 0.8692 - val_loss: 0.3673\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8866 - loss: 0.3202 - val_accuracy: 0.8706 - val_loss: 0.3621\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8887 - loss: 0.3125 - val_accuracy: 0.8712 - val_loss: 0.3595\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8911 - loss: 0.3055 - val_accuracy: 0.8736 - val_loss: 0.3582\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8926 - loss: 0.2989 - val_accuracy: 0.8726 - val_loss: 0.3567\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8953 - loss: 0.2927 - val_accuracy: 0.8726 - val_loss: 0.3565\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8971 - loss: 0.2868 - val_accuracy: 0.8726 - val_loss: 0.3541\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8993 - loss: 0.2811 - val_accuracy: 0.8724 - val_loss: 0.3543\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9020 - loss: 0.2756 - val_accuracy: 0.8722 - val_loss: 0.3537\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9041 - loss: 0.2704 - val_accuracy: 0.8734 - val_loss: 0.3525\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9062 - loss: 0.2652 - val_accuracy: 0.8736 - val_loss: 0.3511\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9084 - loss: 0.2605 - val_accuracy: 0.8758 - val_loss: 0.3496\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.9099 - loss: 0.2558 - val_accuracy: 0.8764 - val_loss: 0.3491\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9117 - loss: 0.2512 - val_accuracy: 0.8766 - val_loss: 0.3480\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9130 - loss: 0.2468 - val_accuracy: 0.8764 - val_loss: 0.3471\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9142 - loss: 0.2426 - val_accuracy: 0.8768 - val_loss: 0.3451\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9159 - loss: 0.2382 - val_accuracy: 0.8778 - val_loss: 0.3435\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9173 - loss: 0.2342 - val_accuracy: 0.8784 - val_loss: 0.3413\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.9188 - loss: 0.2302 - val_accuracy: 0.8792 - val_loss: 0.3402\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9203 - loss: 0.2264 - val_accuracy: 0.8784 - val_loss: 0.3410\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The fit() method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). If you use this dictionary to create a Pandas DataFrame and call its plot() method, you get the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Epoch'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 29],\n",
    "    ylim=[0, 1],\n",
    "    grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8758 - loss: 0.3599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35436591506004333, 0.8772000074386597]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.01, 0.  , 0.85],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you only care about the class with the highest estimated probability (even if that probability is quite low), then you can use the argmax() method to get the highest probability class index for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let’s switch back to the California housing problem and tackle it using the same MLP as earlier, with 3 hidden layers composed of 50 neurons each, but this time building it with Keras. Using the sequential API to build, train, evaluate, and use a regression MLP is quite similar to what we did for classification. The main differences in the following code example are the fact that the output layer has a single neuron (since we only want to predict a single value) and it uses no activation function, the loss function is the mean squared error, the metric is the RMSE, and we’re using an Adam optimizer like Scikit-Learn’s MLPRegressor did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - RootMeanSquaredError: 1.1982 - loss: 1.5386 - val_RootMeanSquaredError: 0.6111 - val_loss: 0.3735\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.6353 - loss: 0.4041 - val_RootMeanSquaredError: 0.6261 - val_loss: 0.3920\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.6069 - loss: 0.3687 - val_RootMeanSquaredError: 0.7316 - val_loss: 0.5352\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5930 - loss: 0.3519 - val_RootMeanSquaredError: 0.6337 - val_loss: 0.4016\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5822 - loss: 0.3391 - val_RootMeanSquaredError: 0.6853 - val_loss: 0.4696\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5733 - loss: 0.3288 - val_RootMeanSquaredError: 0.5726 - val_loss: 0.3278\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5671 - loss: 0.3217 - val_RootMeanSquaredError: 1.0567 - val_loss: 1.1165\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5616 - loss: 0.3155 - val_RootMeanSquaredError: 1.3314 - val_loss: 1.7727\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5576 - loss: 0.3109 - val_RootMeanSquaredError: 1.1147 - val_loss: 1.2426\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5513 - loss: 0.3040 - val_RootMeanSquaredError: 0.8875 - val_loss: 0.7877\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - RootMeanSquaredError: 0.5495 - loss: 0.3020 - val_RootMeanSquaredError: 1.2107 - val_loss: 1.4658\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5475 - loss: 0.2999 - val_RootMeanSquaredError: 1.2177 - val_loss: 1.4827\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5437 - loss: 0.2957 - val_RootMeanSquaredError: 1.1189 - val_loss: 1.2519\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5422 - loss: 0.2941 - val_RootMeanSquaredError: 1.1804 - val_loss: 1.3933\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - RootMeanSquaredError: 0.5377 - loss: 0.2892 - val_RootMeanSquaredError: 0.8892 - val_loss: 0.7907\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.5355 - loss: 0.2869 - val_RootMeanSquaredError: 0.7895 - val_loss: 0.6234\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.5296 - loss: 0.2805 - val_RootMeanSquaredError: 0.5465 - val_loss: 0.2987\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5274 - loss: 0.2782 - val_RootMeanSquaredError: 0.5930 - val_loss: 0.3517\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5232 - loss: 0.2738 - val_RootMeanSquaredError: 0.5321 - val_loss: 0.2831\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.5206 - loss: 0.2710 - val_RootMeanSquaredError: 0.5663 - val_loss: 0.3207\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5275 - loss: 0.2784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API\n",
    "\n",
    "* It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.\n",
    "\n",
    "* Let’s build such a neural network to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_],\n",
    "    outputs=[output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path ? In this case, one solution is to use multiple inputs. For example, suppose we want to send five features through the wide path (features 0 to 4), and six features through the deep path (features 2 to 7). We can do this as follows.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5]) # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6]) # features 2 to 7\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can compile the model as usual, but when we call the fit() method, instead of passing a single input matrix X_train, we must pass a pair of matrices (X_train_wide, X_train_deep), one per input. The same is true for X_valid, and also for X_test and X_new when you call evaluate() or predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - RootMeanSquaredError: 1.5279 - loss: 2.4085 - val_RootMeanSquaredError: 0.9234 - val_loss: 0.8527\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.8081 - loss: 0.6538 - val_RootMeanSquaredError: 0.7173 - val_loss: 0.5145\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.7207 - loss: 0.5197 - val_RootMeanSquaredError: 0.6583 - val_loss: 0.4334\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - RootMeanSquaredError: 0.6810 - loss: 0.4640 - val_RootMeanSquaredError: 0.6671 - val_loss: 0.4451\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.6577 - loss: 0.4328 - val_RootMeanSquaredError: 0.6167 - val_loss: 0.3803\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.6387 - loss: 0.4082 - val_RootMeanSquaredError: 0.6299 - val_loss: 0.3968\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - RootMeanSquaredError: 0.6241 - loss: 0.3897 - val_RootMeanSquaredError: 0.6862 - val_loss: 0.4709\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.6133 - loss: 0.3764 - val_RootMeanSquaredError: 0.6431 - val_loss: 0.4135\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - RootMeanSquaredError: 0.6058 - loss: 0.3672 - val_RootMeanSquaredError: 0.7166 - val_loss: 0.5135\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - RootMeanSquaredError: 0.6000 - loss: 0.3601 - val_RootMeanSquaredError: 0.6627 - val_loss: 0.4392\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5953 - loss: 0.3546 - val_RootMeanSquaredError: 0.7622 - val_loss: 0.5809\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5922 - loss: 0.3509 - val_RootMeanSquaredError: 0.6194 - val_loss: 0.3837\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5890 - loss: 0.3470 - val_RootMeanSquaredError: 1.2028 - val_loss: 1.4467\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - RootMeanSquaredError: 0.5886 - loss: 0.3466 - val_RootMeanSquaredError: 1.3081 - val_loss: 1.7112\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5870 - loss: 0.3446 - val_RootMeanSquaredError: 1.3684 - val_loss: 1.8724\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5872 - loss: 0.3449 - val_RootMeanSquaredError: 1.1385 - val_loss: 1.2961\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5824 - loss: 0.3393 - val_RootMeanSquaredError: 0.8846 - val_loss: 0.7825\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5799 - loss: 0.3363 - val_RootMeanSquaredError: 0.7205 - val_loss: 0.5192\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5770 - loss: 0.3330 - val_RootMeanSquaredError: 0.6731 - val_loss: 0.4530\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - RootMeanSquaredError: 0.5742 - loss: 0.3298 - val_RootMeanSquaredError: 0.6311 - val_loss: 0.3982\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - RootMeanSquaredError: 0.5748 - loss: 0.3304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "history = model.fit((X_train_wide,X_train_deep), y_train, epochs=20, validation_data=((X_valid_wide,X_valid_deep),y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_wide, input_deep], \n",
    "    outputs=[output, aux_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each output will need its own loss function. Therefore, when we compile the model, we should pass a list of losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(\n",
    "    loss=(\"mse\", \"mse\"),\n",
    "    loss_weights=(0.9, 0.1),\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now when we train the model, we need to provide labels for each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - dense_2_RootMeanSquaredError: 1.3484 - dense_2_loss: 1.9095 - dense_3_RootMeanSquaredError: 1.8758 - dense_3_loss: 3.6573 - loss: 2.0842 - val_dense_2_RootMeanSquaredError: 1.1080 - val_dense_2_loss: 1.2273 - val_dense_3_RootMeanSquaredError: 1.2325 - val_dense_3_loss: 1.5186 - val_loss: 1.2569\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.7323 - dense_2_loss: 0.5372 - dense_3_RootMeanSquaredError: 0.8831 - dense_3_loss: 0.7806 - loss: 0.5615 - val_dense_2_RootMeanSquaredError: 0.7289 - val_dense_2_loss: 0.5312 - val_dense_3_RootMeanSquaredError: 0.8095 - val_dense_3_loss: 0.6551 - val_loss: 0.5437\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.6661 - dense_2_loss: 0.4441 - dense_3_RootMeanSquaredError: 0.7950 - dense_3_loss: 0.6323 - loss: 0.4629 - val_dense_2_RootMeanSquaredError: 0.6300 - val_dense_2_loss: 0.3967 - val_dense_3_RootMeanSquaredError: 0.7504 - val_dense_3_loss: 0.5631 - val_loss: 0.4135\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.6438 - dense_2_loss: 0.4148 - dense_3_RootMeanSquaredError: 0.7627 - dense_3_loss: 0.5820 - loss: 0.4315 - val_dense_2_RootMeanSquaredError: 0.5999 - val_dense_2_loss: 0.3598 - val_dense_3_RootMeanSquaredError: 0.7307 - val_dense_3_loss: 0.5338 - val_loss: 0.3773\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - dense_2_RootMeanSquaredError: 0.6313 - dense_2_loss: 0.3989 - dense_3_RootMeanSquaredError: 0.7396 - dense_3_loss: 0.5472 - loss: 0.4137 - val_dense_2_RootMeanSquaredError: 0.5908 - val_dense_2_loss: 0.3490 - val_dense_3_RootMeanSquaredError: 0.7028 - val_dense_3_loss: 0.4938 - val_loss: 0.3635\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6226 - dense_2_loss: 0.3879 - dense_3_RootMeanSquaredError: 0.7176 - dense_3_loss: 0.5152 - loss: 0.4006 - val_dense_2_RootMeanSquaredError: 0.5846 - val_dense_2_loss: 0.3417 - val_dense_3_RootMeanSquaredError: 0.6873 - val_dense_3_loss: 0.4723 - val_loss: 0.3548\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.6162 - dense_2_loss: 0.3800 - dense_3_RootMeanSquaredError: 0.7001 - dense_3_loss: 0.4903 - loss: 0.3910 - val_dense_2_RootMeanSquaredError: 0.6299 - val_dense_2_loss: 0.3966 - val_dense_3_RootMeanSquaredError: 0.7236 - val_dense_3_loss: 0.5235 - val_loss: 0.4094\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.6107 - dense_2_loss: 0.3732 - dense_3_RootMeanSquaredError: 0.6865 - dense_3_loss: 0.4714 - loss: 0.3830 - val_dense_2_RootMeanSquaredError: 0.6688 - val_dense_2_loss: 0.4472 - val_dense_3_RootMeanSquaredError: 0.7866 - val_dense_3_loss: 0.6186 - val_loss: 0.4645\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6058 - dense_2_loss: 0.3671 - dense_3_RootMeanSquaredError: 0.6757 - dense_3_loss: 0.4567 - loss: 0.3761 - val_dense_2_RootMeanSquaredError: 0.9484 - val_dense_2_loss: 0.8990 - val_dense_3_RootMeanSquaredError: 0.9404 - val_dense_3_loss: 0.8841 - val_loss: 0.8979\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6026 - dense_2_loss: 0.3633 - dense_3_RootMeanSquaredError: 0.6692 - dense_3_loss: 0.4479 - loss: 0.3718 - val_dense_2_RootMeanSquaredError: 1.5090 - val_dense_2_loss: 2.2760 - val_dense_3_RootMeanSquaredError: 1.4594 - val_dense_3_loss: 2.1289 - val_loss: 2.2624\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.6018 - dense_2_loss: 0.3623 - dense_3_RootMeanSquaredError: 0.6636 - dense_3_loss: 0.4405 - loss: 0.3701 - val_dense_2_RootMeanSquaredError: 1.1895 - val_dense_2_loss: 1.4142 - val_dense_3_RootMeanSquaredError: 0.9406 - val_dense_3_loss: 0.8844 - val_loss: 1.3618\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - dense_2_RootMeanSquaredError: 0.5977 - dense_2_loss: 0.3574 - dense_3_RootMeanSquaredError: 0.6574 - dense_3_loss: 0.4322 - loss: 0.3649 - val_dense_2_RootMeanSquaredError: 1.2691 - val_dense_2_loss: 1.6098 - val_dense_3_RootMeanSquaredError: 1.5099 - val_dense_3_loss: 2.2789 - val_loss: 1.6775\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.5940 - dense_2_loss: 0.3529 - dense_3_RootMeanSquaredError: 0.6542 - dense_3_loss: 0.4280 - loss: 0.3604 - val_dense_2_RootMeanSquaredError: 0.8763 - val_dense_2_loss: 0.7676 - val_dense_3_RootMeanSquaredError: 0.8712 - val_dense_3_loss: 0.7588 - val_loss: 0.7670\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - dense_2_RootMeanSquaredError: 0.5907 - dense_2_loss: 0.3490 - dense_3_RootMeanSquaredError: 0.6471 - dense_3_loss: 0.4189 - loss: 0.3560 - val_dense_2_RootMeanSquaredError: 0.9492 - val_dense_2_loss: 0.9006 - val_dense_3_RootMeanSquaredError: 1.0303 - val_dense_3_loss: 1.0612 - val_loss: 0.9170\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5872 - dense_2_loss: 0.3449 - dense_3_RootMeanSquaredError: 0.6437 - dense_3_loss: 0.4145 - loss: 0.3519 - val_dense_2_RootMeanSquaredError: 0.6751 - val_dense_2_loss: 0.4557 - val_dense_3_RootMeanSquaredError: 0.7311 - val_dense_3_loss: 0.5344 - val_loss: 0.4637\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5847 - dense_2_loss: 0.3420 - dense_3_RootMeanSquaredError: 0.6396 - dense_3_loss: 0.4092 - loss: 0.3487 - val_dense_2_RootMeanSquaredError: 0.9640 - val_dense_2_loss: 0.9290 - val_dense_3_RootMeanSquaredError: 1.0876 - val_dense_3_loss: 1.1824 - val_loss: 0.9547\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5835 - dense_2_loss: 0.3406 - dense_3_RootMeanSquaredError: 0.6377 - dense_3_loss: 0.4067 - loss: 0.3472 - val_dense_2_RootMeanSquaredError: 0.8965 - val_dense_2_loss: 0.8034 - val_dense_3_RootMeanSquaredError: 1.0129 - val_dense_3_loss: 1.0255 - val_loss: 0.8259\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5831 - dense_2_loss: 0.3401 - dense_3_RootMeanSquaredError: 0.6359 - dense_3_loss: 0.4044 - loss: 0.3466 - val_dense_2_RootMeanSquaredError: 1.0666 - val_dense_2_loss: 1.1372 - val_dense_3_RootMeanSquaredError: 1.0490 - val_dense_3_loss: 1.1000 - val_loss: 1.1339\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5812 - dense_2_loss: 0.3379 - dense_3_RootMeanSquaredError: 0.6329 - dense_3_loss: 0.4006 - loss: 0.3442 - val_dense_2_RootMeanSquaredError: 0.7948 - val_dense_2_loss: 0.6315 - val_dense_3_RootMeanSquaredError: 0.8413 - val_dense_3_loss: 0.7076 - val_loss: 0.6393\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - dense_2_RootMeanSquaredError: 0.5791 - dense_2_loss: 0.3355 - dense_3_RootMeanSquaredError: 0.6298 - dense_3_loss: 0.3968 - loss: 0.3416 - val_dense_2_RootMeanSquaredError: 1.1358 - val_dense_2_loss: 1.2894 - val_dense_3_RootMeanSquaredError: 1.2674 - val_dense_3_loss: 1.6056 - val_loss: 1.3216\n"
     ]
    }
   ],
   "source": [
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep),\n",
    "    (y_train, y_train),\n",
    "    epochs=20,\n",
    "    validation_data=(\n",
    "        (X_valid_wide, X_valid_deep),\n",
    "        (y_valid, y_valid)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - dense_2_RootMeanSquaredError: 0.5874 - dense_2_loss: 0.3452 - dense_3_RootMeanSquaredError: 0.6410 - dense_3_loss: 0.4110 - loss: 0.3517\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The predict() method returns a tuple, and it does not have a return_dict argument to get a dictionary instead. However, you can create one using model.output_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
    "y_pred = dict(zip(model.output_names, y_pred_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # needed to support naming the model\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\", name=\"my_cool_model\")\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_keras_model\", save_format=\"tf\")\n",
    "# model=tf.keras.load_model(\"my_keras_model\")\n",
    "# y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "    sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 13s]\n",
      "val_accuracy: 0.004392764996737242\n",
      "\n",
      "Best val_accuracy So Far: 0.004392764996737242\n",
      "Total elapsed time: 00h 07m 22s\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=5,\n",
    "    overwrite=True,\n",
    "    directory=\"my_fashion_mnist\",\n",
    "    project_name=\"my_rnd_search\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "random_search_tuner.search(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can get the best models like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MRE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can also call get_best_hyperparameters() to get the kt.HyperParameters of the best models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 5,\n",
       " 'n_neurons': 25,\n",
       " 'learning_rate': 0.0006562536901904111,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "top3_params[0].values # best hyperparameter values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
